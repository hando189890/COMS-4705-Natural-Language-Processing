{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "silBI34YK6jK"
   },
   "source": [
    "# **Google Colab Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4CxEtRmK2LO",
    "outputId": "f9c45e7c-01f7-4005-a5cf-ab3e95e06802"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "arwaN6bnD6xz",
    "outputId": "091a0913-a2ec-4d9e-baa3-5335cfc3afb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/dh3071_hw4_files\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/dh3071_hw4_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wh5tDCVoEHHY",
    "outputId": "5a71c838-f1e6-409e-f631-25fd75e0a5a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold.trial\t\t\t       lexsub_main.py\t __pycache__\n",
      "GoogleNews-vectors-negative300.bin.gz  lexsub_trial.xml  score.pl\n",
      "lexsub_main.ipynb\t\t       lexsub_xml.py\n"
     ]
    }
   ],
   "source": [
    "!ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeTbMFp0EJ92"
   },
   "source": [
    "# **Envrionment Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gdPDaVUkEJOh",
    "outputId": "033bb819-9ad8-4070-a326-25003470edd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XwCkl3ltEZ08"
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j6MIU36dEasC",
    "outputId": "30ab81a5-9b92-4687-e1f1-847620f400d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v2yR2LP6EgYL",
    "outputId": "f16adb04-8aa4-424c-84cb-1343e1d4a645"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('interruption.n.02.break'),\n",
       " Lemma('break.n.02.break'),\n",
       " Lemma('fault.n.04.break'),\n",
       " Lemma('rupture.n.02.break'),\n",
       " Lemma('respite.n.02.break'),\n",
       " Lemma('breakage.n.03.break'),\n",
       " Lemma('pause.n.01.break'),\n",
       " Lemma('fracture.n.01.break'),\n",
       " Lemma('break.n.09.break'),\n",
       " Lemma('break.n.10.break'),\n",
       " Lemma('break.n.11.break'),\n",
       " Lemma('break.n.12.break'),\n",
       " Lemma('break.n.13.break'),\n",
       " Lemma('break.n.14.break'),\n",
       " Lemma('open_frame.n.01.break'),\n",
       " Lemma('break.n.16.break')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " wn.lemmas('break', pos='n') # Retrieve all lexemes for the noun 'break'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1S0ewEx7EimL"
   },
   "outputs": [],
   "source": [
    "l1 = wn.lemmas('break', pos='n')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Wa2MxSn0FUHK"
   },
   "outputs": [],
   "source": [
    "s1 = l1.synset() # get the synset for the first lexeme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miRpY2XHFWhW",
    "outputId": "f840f5e4-3369-442b-8215-a97405d7a184"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('interruption.n.02')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xyoVZlhPFYdT",
    "outputId": "4b0c1d1f-e127-4818-ed67-ec603a4149b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('interruption.n.02.interruption'), Lemma('interruption.n.02.break')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.lemmas() # Get all lexemes in that synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FFFwnm9lFbGj",
    "outputId": "79e8e367-4937-4d46-fb73-31d62561931c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'interruption'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.lemmas()[0].name() # Get the word of the first lexeme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "rdHeLvfwFfsp",
    "outputId": "db5bd8fa-4a7c-45f4-b3ee-726a30481b98"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'some abrupt occurrence that interrupts an ongoing activity'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JmHyyq7-Fgga",
    "outputId": "0c6f8eab-dc75-415b-f2a9-4d1f88a5b23e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the telephone is an annoying interruption',\n",
       " 'there was a break in the action when a player was hurt']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N0dOze2_Fixr",
    "outputId": "0fe66f3a-69d3-4218-ce14-fafc41d6fc05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('happening.n.01')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QGTvetEnFlCp",
    "outputId": "924748b0-f587-4bea-8c76-e87bdac805e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dislocation.n.01'),\n",
       " Synset('eclipse.n.01'),\n",
       " Synset('punctuation.n.01'),\n",
       " Synset('suspension.n.04')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iNB_g_bVFm9Q",
    "outputId": "f7ea9ab1-a969-49ec-b031-34b2b0ab83d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.count() # Occurence frequency of this sense of 'break' in the SemCor corpus.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "szLEN-RHFqvW",
    "outputId": "b6c3aa45-729d-44b8-d850-65134c68bfb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: gensim in /usr/local/lib/python3.9/dist-packages (4.3.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.22.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (6.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "yNUNhopHFttv"
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "t17nsYxzFxyR"
   },
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin.gz', binary=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "3UsLIXw0JBGS"
   },
   "outputs": [],
   "source": [
    "v1 = model.get_vector('computer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wX5JnbFDJD_S",
    "outputId": "633212b1-7008-4f48-bd58-60687a86d5d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tq9T0rB7JGaw",
    "outputId": "0c818c18-eea8-4113-b27a-57abf7240f25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_pqAAuRPJHRl",
    "outputId": "54997cfa-726e-43e7-bbaa-2be49713c46d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3339888"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('computer','calculator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XyyHuWjlJKFL",
    "outputId": "a0542a7a-b805-4596-ff0d-56e5cafe0304"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26003766"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('computer','toaster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9IrgwBzJLgi",
    "outputId": "ec81ebeb-095e-4165-e403-908f31f87022"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12194333"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('computer','dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3u6f5NLKJMzL",
    "outputId": "b3ed2a70-9c73-4481-f354-6bdcc5da8ab3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09933449"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('computer','run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "LdGSyDGvJlPB"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "zzD8sdAVJl4J"
   },
   "outputs": [],
   "source": [
    "def cos(v1,v2):\n",
    " return np.dot(v1,v2) / (np.linalg.norm(v1)*np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8Ny8-wYJpi6",
    "outputId": "daf7365f-53a9-44fb-e030-5f104786d7d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33398885"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos(model.get_vector('computer'), model.get_vector('calculator'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fx4eMNvLKFJs",
    "outputId": "9a77ac33-6d7b-4408-dfec-b4891d5452e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gaD2iv2KJju"
   },
   "source": [
    "# **Getting Started**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FHvENt9KXYO"
   },
   "source": [
    "**Import lexsub_xml.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "h7BeYzgDKGQG"
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from xml.etree.ElementTree import tostring\n",
    "import sys\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "class Context(object):\n",
    "    \"\"\"\n",
    "    Represent a single input word with context.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cid, word_form, lemma, pos, left_context, right_context): \n",
    "        self.cid = cid\n",
    "        self.word_form = word_form\n",
    "        self.lemma = lemma\n",
    "        self.pos = pos\n",
    "        self.left_context = left_context\n",
    "        self.right_context = right_context\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<Context_{cid}/{lemma}.{pos} {left} *{word}* {right}>\".format(cid=self.cid, lemma = self.lemma, pos = self.pos, left = \" \".join(self.left_context), word=self.word_form, right=\" \".join(self.right_context))\n",
    "\n",
    "class LexsubData(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.total_count =  1\n",
    "        pass\n",
    "\n",
    "    def process_context(self, context_s):\n",
    "        head_re = re.compile(\"<head>(.*)</head>\")\n",
    "        match =  head_re.search(context_s)\n",
    "        target = match.groups(1)[0]\n",
    "        context_left = context_s[:match.start()]\n",
    "        context_right = context_s[match.end():]\n",
    "        return target, context_left.split(), context_right.split()\n",
    "\n",
    "    def parse_lexelt(self, lexelt):\n",
    "        lex_item = lexelt.get('item')\n",
    "        parts = lex_item.split('.')\n",
    "        if len(parts) == 3:\n",
    "            lemma, pos = parts[0], parts[2]\n",
    "        else: \n",
    "            lemma, pos = parts[0], parts[1]\n",
    "\n",
    "        for instance in lexelt:\n",
    "            assert instance.tag==\"instance\"\n",
    "            context = instance.find(\"context\")                     \n",
    "            context_s = \"\".join([str(context.text)] + [codecs.decode(ET.tostring(e),\"UTF-8\") for e in context])\n",
    "            word_form, left_context, right_context = self.process_context(context_s)\n",
    "            yield Context(self.total_count, word_form, lemma, pos, left_context, right_context)\n",
    "            self.total_count += 1\n",
    "\n",
    "    def parse_et(self,et):\n",
    "       assert et.tag == \"corpus\"\n",
    "       for lexelt in et: \n",
    "            assert lexelt.tag == \"lexelt\"\n",
    "            for annotation in self.parse_lexelt(lexelt):\n",
    "                yield annotation\n",
    "\n",
    "\n",
    "def read_lexsub_xml(*sources):\n",
    "    \"\"\"\n",
    "    Parse the lexical substitution data and return an iterator over Context instances.\n",
    "    \"\"\"\n",
    "    lexsub_data = LexsubData()\n",
    "    for source_f in sources:\n",
    "        et = ET.parse(source_f)\n",
    "        for annotation in lexsub_data.parse_et(et.getroot()):\n",
    "            yield annotation\n",
    "    \n",
    "# if __name__==\"__main__\":\n",
    "\n",
    "#     for context in read_lexsub_xml(sys.argv[1]):\n",
    "#         print(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IO9pn9NbTBuE",
    "outputId": "198c562c-6632-41dd-dc45-7cd2d30b9499"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Context_1/bright.a During the siege , George Robertson had appointed Shuja-ul-Mulk , who was a *bright* boy only 12 years old and the youngest surviving son of Aman-ul-Mulk , as the ruler of Chitral .>\n",
      "<Context_2/bright.a The actual field is not much different than that of a 40mm , only it is smaller and quite a bit noticeably *brighter* , which is probably the main benefit .>\n",
      "<Context_3/bright.a The roses have grown out of control , wild and carefree , their *bright* blooming faces turned to bathe in the early autumn sun .>\n",
      "<Context_4/bright.a He was *bright* and independent and proud .>\n",
      "<Context_5/bright.a In fact , during at least six distinct periods in Army history since World War I , lack of trust and confidence in senior leaders caused the so-called best and *brightest* to leave the Army in droves .>\n",
      "<Context_6/bright.a An evening of classical symphonic music , played by the next generation stars in the American orchestral scene , can be savored at the New World Symphony , a special Miami institution that nurtures the best and *brightest* young symphonic musicians .>\n",
      "<Context_7/bright.a There are sound reasons for concluding that the long-run picture remains *bright* , and even recent signals about the current course of the economy have turned from unremittingly negative through the late fall of last year to a far more mixed set of signals recently .>\n",
      "<Context_8/bright.a Snow covered areas appear *bright* blue in the image which was taken in early spring and shows deep snow cover .>\n",
      "<Context_9/bright.a She turns eyes *bright* with excitement towards Fiona , still tugging on the string of the minitiature airship-cum-dance card she has just received at the door .>\n",
      "<Context_10/bright.a A short excerpt : I was praying in private until someone got the *bright* idea of starting a Presidential Prayer Team .>\n",
      "<Context_11/film.n So , unlike studio films , independent *films* cannot be conceptually geared to a marketing campaign , or used to recruit merchandising tie-ins .>\n",
      "<Context_12/film.n The packed screening of about 100 high-level press people loved the *film* as well .>\n",
      "<Context_13/film.n I think most filmmakers for the most part right now they’re thinking about the DVD when they go in to production because the reality is DVD is where the great majority of your audience is going to experience the *film* .>\n",
      "<Context_14/film.n Dune makes the second Lynch *film* to be released in a consumer HD format ( Mulholland Drive on D-VHS being the first ) .>\n",
      "<Context_15/film.n Film Music Literature Cyberplace - Includes *film* reviews , message boards , chat room , and images from various films .>\n",
      "<Context_16/film.n His feature *film* debut HEROES / DE ST&#195;&#152;RSTE HELTE ( 1996 ) won awards at Rouen and Madrid .>\n",
      "<Context_17/film.n ( Some people keep their TVs on for company. ) In Malta , news is the main reason we turn to TV , followed by *films* , talk shows , documentaries , serials , and music , in that order .>\n",
      "<Context_18/film.n The *film* shows Afghan mercenaries to be involved with the separatists , suggesting that the present struggle in Kashmir has been hijacked by foreign extremists , who are shown discussing the loss of Bangladesh in the 1971 war , providing it as a justification for their present acts of revenge .>\n",
      "<Context_19/film.n A fine score by George Fenton ( THE CRUCIBLE ) and beautiful photograhy by Roger Pratt add greatly to the effectiveness of the *film* .>\n",
      "<Context_20/film.n The success of Autry ' s early *films* was not enough to save Mascot Pictures , which collapsed under the weight of debts held by Consolidated Film Laboratories , which did Mascot 's film processing .>\n",
      "<Context_21/take.v That 's not to say the process of actual negotiating is n't *taking* place .>\n",
      "<Context_22/take.v \" Hugh Grant and Alan Rickman , as Edward and Col. Brandon respectively , *took* the most chances and the various reviewers therefore either love or hate their performances .>\n",
      "<Context_23/take.v It should n't *take* that long .>\n",
      "<Context_24/take.v It only affects the start up time of a program , and for a process that *takes* several months ( his code was computing the 196 Palindrome Quest ) , it does not matter if the initialization code takes 1/1,000th of a second or 1/10,000th of a second .>\n",
      "<Context_25/take.v If we *take* the factual context in which the term is used into consideration , then its extension becomes limited , owing to the context .>\n",
      "<Context_26/take.v If you do n't *take* the risk of dying by driving to the store , your house could collapse on you and kill you anyway .>\n",
      "<Context_27/take.v The Governor *took* the big sheets of imitation parchment , glanced over them , signed his name to each , laid down the pen , and handed the papers across the table to Dreier .>\n",
      "<Context_28/take.v O'Neill and the two men who worked under his supervision maintained the avenue , raking the thin gravel and removing any weed that tried to *take* root in the stony earth .>\n",
      "<Context_29/take.v Even if the Anglo-French Summit did not *take* place until next year , the Prime Minister and President Chirac were still due to see each other in November and December .>\n",
      "<Context_30/take.v 40 Day-to-day financial and operational management is the responsibility of the Chief Officer , who *took* up her post in June 2001 .>\n",
      "<Context_31/tight.r Anyway , my pants are getting *tight* .>\n",
      "<Context_32/tight.r With the physical market has *tight* as it has been in memory , silver could fly at any time .>\n",
      "<Context_33/tight.r More ... Specialty coffee market quiet , supplies *tight* Posted at 2:57 PM by Robert Badgett By Bruce Kamich NEW YORK , June 6 ( Reuters ) - Specialty coffee dealers said on Friday that business was unusually quiet with most retailers ' sales numbers down from a year ago , but prices for choice beans remained firm with supplies short until the next crops become available .>\n",
      "<Context_34/tight.r If your money is *tight* do n't cut corners .>\n",
      "<Context_35/tight.r Each child lies inside an Isolette incubator , a clear acrylic rectangle with ample room for a half-sized premature baby , though the quarters become *tight* for the full-term eight-pounders .>\n",
      "<Context_36/tight.r \" It can be intimidating at first , because they wrap their arms pretty *tight* around you , and everything they latch onto is pretty much headed straight to their mouth , \" Schmitz said .>\n",
      "<Context_37/tight.r The incisions will feel *tight* for the first 24-48 hours .>\n",
      "<Context_38/tight.r Except for the soldiers , Goth was locked up *tight* .>\n",
      "<Context_39/tight.r Nathan Robins : Did well to keep *tight* on the Left winger and was harshly judged by the referee on several occasions to have fouled the opposing player when I felt he just out muscled him .>\n",
      "<Context_40/tight.r I know that the market is *tight* right now .>\n",
      "<Context_41/bar.n That 's not a very high *bar* .>\n",
      "<Context_42/bar.n This more upright position is most easily and affordably achieved through slapping a riser bar on your setup , and only requires you to buy a bar instead of a *bar* and stem .>\n",
      "<Context_43/bar.n For twelve hours Livewire will be broadcasting live from the blue *bar* of Union House at UEA in an attempt to raise as much money as possible for a very worthy cause .>\n",
      "<Context_44/bar.n The British government imposed a colour *bar* in its colonies , so young blacks went in only for law or medicine where they could make a living without government support .>\n",
      "<Context_45/bar.n Put granola *bars* in bowl .>\n",
      "<Context_46/bar.n It 's been a criticism of IE 's scrollbar CSS and also stands for the status *bar* .>\n",
      "<Context_47/bar.n 2 ) Straddling the center bar , your child should be able to keep both feet flat on the ground with about a 1-inch clearance between the crotch and the *bar* .>\n",
      "<Context_48/bar.n Seventy-five percent of my clientele that comes in there , they are just like a person on a Friday afternoon going into a *bar* , and he sits at the counter , and the bartender knows what he wants to drink .>\n",
      "<Context_49/bar.n The night is long at the numerous other discos and clubs , but for those seeking something more sedate there are quieter , sophisticated *bars* in the hotels .>\n",
      "<Context_50/bar.v Abstract : Analysis of contact between two chromosomal races of house mice in northern Italy show that natural selection will produce alleles that *bar* interracial matings if the resulting offspring are unfit hybrids .>\n",
      "<Context_51/cross.n When Time magazine 's cover portrays millennium nuts as deranged , crazy Christians holding a *cross* as it did last month , boycott their magazine and the products it advertises .>\n",
      "<Context_52/cross.n Four-Set in a *cross* , the points meeting in water surrounded by luminous crescents .>\n",
      "<Context_53/cross.n It was designed in the form of a *cross* with a cast iron sword placed where the cross members join .>\n",
      "<Context_54/cross.n Triticale , a *cross* between wheat and rye , matures later than rye but earlier than wheat .>\n",
      "<Context_55/cross.n Old Nick got tired of cussing , was humiliated at being sat on , and hurting like the torments of Hell for being so close to the *cross* .>\n",
      "<Context_56/cross.n By 1924 he managed to transmit across a few feet the flickering image of a Maltese *cross* and on 26th January 1926 he gave the world 's first demonstration of true television in his attic workshop before some fifty scientists .>\n",
      "<Context_57/cross.n He appeared to his apostles and spoke to them about God 's kingdom. ' Acts 1:3 Jesus took the consequences of our self-centredness by giving up his life on the *cross* .>\n",
      "<Context_58/cross.n If power cycling occurs , care must be taken to account for the \" dead time \" between shutdown and power up when the latchup *cross* section is evaluated .>\n",
      "<Context_59/cross.n \" Mixed race people represent a diverse *cross* section of racial , ethnic , and cultural heritages , with many multiracial individuals identifying with multiple communities , \" the organizations stated .>\n",
      "<Context_60/cross.a I can only judge keyboards by going into somewhere like PC World and physically trying them , and I do not want to go into somewhere like PC World , as I do not want to get *cross* .>\n",
      "<Context_61/finally.r Mr. Hall 's old factory is still on Oklahoma Avenue , but the metal fabrication plant where Mr. Larson worked *finally* closed last year after withering for decades .>\n",
      "<Context_62/finally.r None *Finally* , this new rule will also have the effect of encouraging existing corporations to produce safer products , in keeping with the public policy goals that underlie product liability law generally. [ Fn .>\n",
      "<Context_63/finally.r However , this easy clearing method has muddled the issue quite a bit , since now Explorer is not actually being cleared at all , while Gecko browsers have *finally* been corrected so they do clear all previous floats .>\n",
      "<Context_64/finally.r None *Finally* , Adam sees the ID card being used as an authenticator because it might be declared &#8220;trustworthy&#8221; .>\n",
      "<Context_65/finally.r He said , \" OK , first , I 'd like to have a face like Clark Gable , then , I 'd like a build like Arnold Schwarzenegger , and *finally* , I 'd like sexual equipment like this here horse I 'm riding .>\n",
      "<Context_66/finally.r None *Finally* , I interviewed Eric Howes , a noted spyware researcher at the University of Illinois , who has found that today 's most popular anti-spyware software packages are far less effective than many believe ( see sidebar , below ) .>\n",
      "<Context_67/finally.r However , you will get those NSF fees reimbursed by the bank as well - it will just come when they *finally* process everything together .>\n",
      "<Context_68/finally.r None *Finally* , the Army has conducted range characterization activities regarding the potential for contamination from munitions residues at 17 ranges throughout the United States , assessing the different types of ranges used by the Army .>\n",
      "<Context_69/finally.r None *Finally* , it is outlined how a mesoscopic theory should be constructed for a particular scanning tunneling microscopy experiment in order to overcome the failure of a corresponding reaction&#150;diffusion model to quantitatively reproduce the experiments .>\n",
      "<Context_70/finally.r None *Finally* , the proposed disposal rule would apply to transfer agents registered with the Commission .>\n",
      "<Context_71/find.v Up to sixty percent of the fatty acid content in the grasses on the plains contain omega-3 and are *found* in abundance in buffalo allowed to graze on the natural grasses .>\n",
      "<Context_72/find.v If you find yourself caught up in negative thoughts and *find* that you suddenly expect the worst it will be impossible to perform at your peak .>\n",
      "<Context_73/find.v Search Customer Reviews 9 of 10 people *found* the following review helpful : Early feminist literature - memorable , November 21 , 2000 Reviewer : M. J. Smith ( Seattle , WA USA ) - See all my reviews This book consists of a gem of a story and a mediocre afterward .>\n",
      "<Context_74/find.v Well they have a friend named Morgan and Morgan told them to *find* an object that he wants .>\n",
      "<Context_75/find.v Consistent with previous findings , lack of congruence was *found* to be a precursor of intrusiveness .>\n",
      "<Context_76/find.v nokia mobile phone cases , motorola cell phone cases , motorola cell phone case , body glove cell phone case I think the best place where you can *find* CELL PHONE CARRYING CASE is eBay .>\n",
      "<Context_77/find.v Oh , and as far as the Kool-Aid jokes , *find* your own material .>\n",
      "<Context_78/find.v But much that we once accepted as inevitable , we now *find* absolutely intolerable .>\n",
      "<Context_79/find.v SpeedUpMyPC automatically *finds* the best settings for your PC and carefully controls your system resources to give you the best performance .>\n",
      "<Context_80/find.v If Bessler had indeed discovered some mechanical way of creating perpetual motion , perhaps the only way it is explainable is if he had *found* a way of extracting the energy from this Aether .>\n",
      "<Context_81/fix.v The Transcendental Meditation people advertised this : \" Meditation can *fix* many sicknesses .>\n",
      "<Context_82/fix.v Now , I 'm not sure how I went from missing two weeks to six , but intend to *fix* that as I go .>\n",
      "<Context_83/fix.v ' ' I feel I can get a lot more done as a selectman by being innovative and *fixing* the problems we have with cash flows , because they occur every year .>\n",
      "<Context_84/fix.v Getting back to the day when doctors looked at the whole person .and did not expect a pill to *fix* the mind .>\n",
      "<Context_85/fix.v And thanks to our users , we now have around 30 engines in the database ... New features : - Better layout - Better copy - Small bugs *fixed* Bugs : - ie hell + much more Posted by eric at 05:24 PM | Comments ( 3 ) Investment News As part of the new international expansion strategy 24hdc.com now accepts USD for investments .>\n",
      "<Context_86/fix.v Er , tilty. by anna at July 17 , 2003 03:37 PM yeah , in our case , whoever did the foundation fucked up royally. when the house settled , it was fubar. should be pretty easy to *fix* though...just a matter of getting the pilings set to the right heights. by JC at July 17 , 2003 06:32 PM add a comment Name : Email Address : URL : Remember personal info ?>\n",
      "<Context_87/fix.v I guess I 'll be able to hit the hot button many times as I 'm always at the dealer getting my car *fixed* .>\n",
      "<Context_88/fix.v The long-term problem with Social Security after 2042 could be totally *fixed* by raising the cap on income to a level needed to generate sufficient income to enable the system to continue to pay 100 percent indefinitely .>\n",
      "<Context_89/fix.v The only way to *fix* this is for linux to get enough market share to be able to make demands for hardware support. [ reply ] [ top ] [ &#194; &#187; ] Releasing specs is the only answer. by The Nose Who Knows - Feb 26th 2001 04:29:40 &amp;gt; The other reason why vendors do n't support linux &amp;gt; most of the time for commidity hardware such as &amp;gt; webcam is low returns on investments .>\n",
      "<Context_90/fix.v But if no prayers can alter your purpose , dear one , husband , if you are so *fixed* on going , take me with you , also !>\n",
      "<Context_91/manage.v Suddenly there was a scattering of fire , which three outfielders caught the brunt ; the centerfield was hit and was captured , left and right field *managed* to get back to our lines .>\n",
      "<Context_92/manage.v \" C158 ( cf ex R145 ) \" The Provincial in Councilor the Superior ofthe Delegation in Councilsets the financial competency of local Superiorsand their Councilsand determines which assets can be *managed* by individualOblates and by local Superiors and their Councils .>\n",
      "<Context_93/manage.v BUSINESS DEVELOPMENT MANAGER STRATEGIC ALLIANCES This individual will be responsible for coordinating , negotiating , launching , and *managing* Accuity 's partner relationships .>\n",
      "<Context_94/manage.v A married woman retains ownership of any property she brought to the marriage , but the husband has the right to *manage* the property and to enjoy profits from the property .>\n",
      "<Context_95/manage.v We do not need to ask for your specific permission to do these things , as explained below : Treatment Partners health care providers will use and share your health information to provide and *manage* your health care and related services .>\n",
      "<Context_96/manage.v According to a White House press release , al-Taqwa and its affiliates \" raise , *manage* , invest , and distribute funds for al-Qaeda ; provide terrorist supporters with internet service and secure telephone communications ; and arrange for the shipment of weapons .>\n",
      "<Context_97/manage.v That is , if the average person ( say this is 98 % of people ) amasses 10 things , if I *manage* to acquire 20 things then perhaps my account is not worth twice as much but maybe 10x or 100x as much as average .>\n",
      "<Context_98/manage.v There are different types of *managed* care systems .>\n",
      "<Context_99/manage.v Saddam Hussein did n't *manage* to defeat the Iranians .>\n",
      "<Context_100/manage.v The M107 program is *managed* by the Project Manager Soldier Weapons with engineering support provided by Picatinny&#194;&#146;s Armament Research , Development and Engineering Center .>\n",
      "<Context_101/neat.a It is really a *neat* plan , well documented and a model for libraries that are still working on their plans. ~ ~ ~ Corrections to April 2003 issue of LDD On the Road : Some things slipped by when putting together last month&#8217;s issue of LDD On the Road .>\n",
      "<Context_102/neat.a And the prize for *neatest* , simplest idea has to go to britkid.org , a resource for opening children 's eyes to the diversity of our culture. www.skoool.com www.nrich.maths.org.uk www.stagework.org.uk www.learningcurve.gov.uk www.britkid.org Email Hotmail is the free email service everyone knows .>\n",
      "<Context_103/neat.a Over the course of the 20th century scholars have learned that such images tried to make messy reality *neater* than it really is .>\n",
      "<Context_104/neat.a Strong field patterns created by hedgerows give the landscape a *neat* , well structured appearance .>\n",
      "<Context_105/neat.a Besides a list of specific things you wish they would talk about , the following things are helpful additions to the *neat* packet you hand them when you ask them to write the letter .>\n",
      "<Context_106/neat.a \" -4 Time IROC Champion Mark Martin Indy 500 , CART and IROC champion , Al Unser Jr. said , \" I watched my father and uncle Bobby race in IROC and as a kid I thought it would be really *neat* if someday I would get an opportunity to run IROC .>\n",
      "<Context_107/neat.a The Society for Academic Emergency Medicine is a *neat* little bunch of people who are dedicated to furthering the interests of academia and research in the youngest of the medical specialties .>\n",
      "<Context_108/neat.a A weblog by Tom Coates who thinks up *neat* stuff for Yahoo !>\n",
      "<Context_109/neat.a But not as odd as the 35 others who bedded down with him each night in a *neat* row down the street on a carpet of cardboard boxes and multicoloured raffia beach mats .>\n",
      "<Context_110/neat.a Link to the full FEDERAL GOVERNMENT DEBT REPORT with pictures - there are 9 color graphics that tell the whole story - - so , give the next page time to load those *neat* pictures .>\n",
      "<Context_111/rich.a What are the important variables that create a *rich* online learning experience , one that makes real improvements in academic practice ?>\n",
      "<Context_112/rich.a Trees on Anmyeondo used to be thick and lush to the extent of prompting a saying , Â¡Â°You can become *rich* with an axe.&#194;&#161;&#194;&#177; But now only few trees are left due to reckless deforestation since the time of Korea&#194;&#161;&#194;&#175;s liberation from Japanese colonial rule .>\n",
      "<Context_113/rich.a No , we 're not talking about the fortunes of a *rich* and powerful democracy .>\n",
      "<Context_114/rich.a Functional Foods and Drinks , Sports Drinks , Slimming , Supplements Functional foods : Glico launches this chocolate *rich* in GABA for its relaxing effect .>\n",
      "<Context_115/rich.a Africas central problems in the WTO revolve around the imbalances and biases created by *rich* countries in the Uruguay Round Agreement ( URA ) .>\n",
      "<Context_116/rich.a Today half the world 's population lives on less than $ 2 a day , 80 percent of the global population has only 20 percent of global GDP , and within each country there is a massive imbalance between *rich* and poor .>\n",
      "<Context_117/rich.a Here Wagner , in depicting every shade of sexual love , developed a style *richer* and more chromatic than anyone had previously attempted , using dissonance and its urge for resolution in a continuing pattem to build up tension and a sense of profound yearning ; Act 2 is virtually a continuous love duet , touching every emotion from the tenderest to the most passionately erotic .>\n",
      "<Context_118/rich.a He brings an incredibly *rich* and diverse background that includes everything from executive coaching , learning &amp; development and management consulting , to senior operations roles , mixed with a masters in organizational development .>\n",
      "<Context_119/rich.a None *Rich* people manage their money well .>\n",
      "<Context_120/rich.a I also think that it will probably take the \" sword \" of nations ( ala Rom 13 ) combined with the good news offered by the body of Christ to touch the hearts and change the ways of the \" rich Africans \" ( and *rich* Americans and other westerners , frankly ) to bring change .>\n",
      "<Context_121/severely.r Rubinstein held the gambit pawn with 4.Bf4 and 7.Qd5 , but his neglect of kingside development was *severely* punished .>\n",
      "<Context_122/severely.r This veteran , the oldest pensioner in Great Britain , entered the army in 1758 , and was *severely* wounded at the battle of Quebec under General Wolfe , in consequence of which he became an out-pensioner of Chelsea Hospital , and continued so for the period of seventy-five years .>\n",
      "<Context_123/severely.r Perhaps the effect of West Nile Virus is sufficient to extinguish endemic birds already *severely* stressed by habitat losses .>\n",
      "<Context_124/severely.r She looked as *severely* as she could muster at Draco .>\n",
      "<Context_125/severely.r A day before he was due to return to the United States Patton was *severely* injured in a road accident .>\n",
      "<Context_126/severely.r Use market tools to address environmental issues , such as eliminating subsidies for industries that *severely* harm the environment , like coal .>\n",
      "<Context_127/severely.r This picture was *severely* damaged in the flood of 1913 and has rarely been seen until now .>\n",
      "<Context_128/severely.r I was very disappointed when the author did not go into detail about how he regained his faith after having it *severely* undermined by his early studies in theology at university .>\n",
      "<Context_129/severely.r We do continue to support research on the differentiation of adult precursor cells into beta cells , but that 's a *severely* limited field in terms of how successful it has been .>\n",
      "<Context_130/severely.r Mutual Funds are so *severely* conflicted that they will not avail themselves of the alleged benefits of the proposed rule .>\n",
      "<Context_131/stand.v Leaders of some of the most powerful states in the world *stand* by and give the impression that this is just the new way of life for Zimbabweans .>\n",
      "<Context_132/stand.v We cannot *stand* as helpless spectators while millions die for want in a world of plenty .>\n",
      "<Context_133/stand.v She knew that behind this remarkable new event that had overwhelmed AllahÂs Messenger ( sallallahu Âalayhi wa sallam ) lay something great that Allah ( Subhanahu wa taÂala ) had prepared for His Messenger , so she spoke her kind and sweet words of encouragement , filling him with confidence , tranquility and firm conviction : ÂBe of good cheer , O cousin , and *stand* firm .>\n",
      "<Context_134/stand.v Liberals(135)+NDP(19)=154=the usual yapping NDP of no consequence Liberals(135)+Bloc(54)=189=oui the government *stands* or non it falls Do n't count on the Bloc to squander their good fortune like they did the last time they had 54 either .>\n",
      "<Context_135/stand.v 1 MCAS *stands* for the Massachusetts Comprehensive Assessment System , a standards test administered to students in grades 3 , 4 , 5 , 6 , 7 , 8 , and 10 throughout the state .>\n",
      "<Context_136/stand.v And secondly , the Consensus demonstrated to the World that Africa no longer *stands* on the fridges or sit on the fence when issues likely to have impacts on its economies and its people are being discussed .>\n",
      "<Context_137/stand.n Sapling and Pole Stages to Maturity Growth and Yield- Mature northern red oaks are usually from 20 to 30 m ( 65 to 98 ft ) tall and 61 to 91 cm ( 24 to 36 in ) in d.b.h. in undisturbed *stands* on good sites .>\n",
      "<Context_138/stand.n The *stand* is not included .>\n",
      "<Context_139/stand.n Here , its walnut case has been mounted on an adjustable *stand* to make one of the earliest desk sets .>\n",
      "<Context_140/stand.n The denomination essentially voted to take a neutral *stand* on many varying interpretations of Genesis 1. Feedback Letter &gt;From : Stephen Craig Comment : First , let me compliment all of you for a great site .>\n",
      "<Context_141/well.r Attorney General 's Page The Connecticut Attorney General 's website includes a discussion of current health topics , including HMOs , Medicare , current Connecticut health legislation , and insurance issues as *well* as information on your rights when it comes to making health care decisions .>\n",
      "<Context_142/well.r We needed to plan *well* in advanced to give schools enough warning but not too much choice on times and dates as this seemed to make decisions harder !>\n",
      "<Context_143/well.r And be ready to move elsewhere if you are not being treated *well* .>\n",
      "<Context_144/well.r Treatment of physical problems , particularly chronic ones , is possible as *well* as psychological therapy .>\n",
      "<Context_145/well.r Fades the light ; And afar Goeth day , And the stars Shineth bright , Fare thee *well* ; Day has gone , Night is on .>\n",
      "<Context_146/well.r Half the phones , half the computers , half the consumer electronic products we buy are not as *well* made or designed as the other half .>\n",
      "<Context_147/well.r None *Well* , perhaps not .>\n",
      "<Context_148/well.r Cupertino-based Apple is known for aggressively protecting its intellectual property , as *well* as its image .>\n",
      "<Context_149/well.r None *Well* , one of Alf 's intentions when he first conceived the Newsletter was that it should serve as a continuous record of the activities of the Society , and as we all know , the contents of a web page can change or disappear as fast as a bottle of wine at Hogmanay !>\n",
      "<Context_150/well.r None *Well* now we have. ' Plain English Campaign is n't stopping there , though .>\n",
      "<Context_151/wild.a Modern hunting methods have been introduced , undermining the traditional hunting practices of the local people who have for generations sought to protect and preserve *wild* life .>\n",
      "<Context_152/wild.a It is presumed that this is because the level of infection of IHHN virus in the *wild* population is relatively low , and when these wild stocks are held in captivity , the virus quickly spreads from infected broodstock to non-infected broodstock .>\n",
      "<Context_153/wild.a Freya , orphaned as a baby and now something of a *wild* spirit , shares her secrets with Danny in their private place on the nearby rocky crags .>\n",
      "<Context_154/wild.a These wounds may be from a variety of sources : fish hooks , barbed wire , lawnmowers , traps , tree branches , cats , dogs , bullets , or , even other *wild* animals .>\n",
      "<Context_155/wild.a In the Genealogy Section a *wild* story about someone 's Great Great Grandfather !>\n",
      "<Context_156/wild.a Now it is the GW doomsayers that ignore similar geological evidence that show *wild* and mini climatic swings throughout the earth&#8217;s history .>\n",
      "<Context_157/wild.a Lovely venue ( well as long as you go in for the *wild* wallpaper ) , fantastic sound system , great staff , nice cocktails and a great time had by all .>\n",
      "<Context_158/wild.a You 'll accuse me of being off track , and rightly so , but should n't we first ask what solution our dear Islam has provided for satisfying your *wild* God-given instincts , beside suppressing them for years until you get the chance to get married ?>\n",
      "<Context_159/wild.a The riverine habitat is extremely beautiful and the chances of seeing large *wild* animals are high .>\n",
      "<Context_160/wild.n An endangered species is one that could become extinct in the *wild* in 10 to 20 years , if nothing is done to protect it .>\n",
      "<Context_161/can.n • What happened to the big , new garbage *can* at Church and Chambers Streets ?>\n",
      "<Context_162/can.n After the coin has been sleeved , there is no hesitation as the *can* apparently covers the coin in the LH .>\n",
      "<Context_163/can.n Instead of cleverly tricking Prosser into lying down in the mud , Ford simply distracts the workmen with a shopping trolley full of *cans* of lager which he just happens to have with him .>\n",
      "<Context_164/can.n No hazardous materials such as paint , noxious chemicals , solvents , oil , petrol *cans* , gas bottles , tyres , asbestos , vehicle batteries , medical or biological waste .>\n",
      "<Context_165/can.n Sources of standing water include old tires , metal *cans* , ceramic pots , clogged drain covers , wading pools , pool covers , bird baths , and rain barrels.&#8221; Visit the CDC West Nile website at http://www.cdc.gov/ncidod/dvbid/westnile / .>\n",
      "<Context_166/can.n Q : Do you take steel *cans* at the curbside ?>\n",
      "<Context_167/can.n Aluminum & Steel Cans - Rinse aluminum and steel *cans* .>\n",
      "<Context_168/can.n Packed the soil itself into huge trash *cans* and in the 14 truckloads , two a day , carried soil to new house .>\n",
      "<Context_169/can.n Facilities are available for the recycling of paper , glass , *cans* , textiles , shoes , plastic bottles , cardboard , and oil .>\n",
      "<Context_170/can.n Jan replies ... Hi Linda , One cat owner reported , \" We are now back on maintenance dose of 3/4 tablespoon of essiac mixed with one tablespoon of tuna juice ( the spring water from a *can* of tuna ) .>\n",
      "<Context_171/dark.n So we all went out to dinner , and I found myself sitting between light and dark , which is where we all are , is n't it , and I kept feeling more attracted to the *dark* .>\n",
      "<Context_172/dark.n I think that the work I do is done in the *dark* .>\n",
      "<Context_173/dark.n \" One was so in the *dark* as to what they wanted , \" complained Edwin Lutyens , the greatest British architect of the day , \" the site so lovely , the conditions so difficult .>\n",
      "<Context_174/dark.n I think overtly making out in public can be kept somewhere in the *dark* .>\n",
      "<Context_175/dark.n Conversely , the most successful CEO 's seem to have a knack for finding their way in the *dark* .>\n",
      "<Context_176/dark.n So to be \" able to read the handwriting on the wall \" has ever since been a metaphor for being able to see what 's coming , especially when those around you remain in the *dark* .>\n",
      "<Context_177/dark.n Go out to get some chow , and they had all slipped away in the *dark* of the night .>\n",
      "<Context_178/dark.n Part of it is her unique view of the world , whether walking around the room telling people they are her friends , or riding around in the car after *dark* telling me she wants to &#8220;touch the purple night.&#8221; Part of it is that she has Down syndrome .>\n",
      "<Context_179/dark.n Another remarkable subject is \" Reality ( play loud ) \" , the artist embarks in a alucinogeno trip soul simply to demonstrate its vocal capacities , africanismo and the *dark* to us in a threatening atmosphere .>\n",
      "<Context_180/dark.n The cells were resuspended in 0.1 % saponin wash and mixed in the *dark* for 1 h. The cells were pelleted and the supernatant was discarded .>\n",
      "<Context_181/examination.n However , the *examination* will be detailed if the applicant expressly requests it ( for example , at the same time as filing the Demand ) , or if the applicant files amendments and/or arguments ( for example , in response to the International Search Report , with the Demand or in response to a Written Opinion ; see below ) .>\n",
      "<Context_182/examination.n From the previous *examination* last week the auto-immune deficiency could also be excluded .>\n",
      "<Context_183/examination.n Readers will appreciate this well-researched *examination* .>\n",
      "<Context_184/examination.n As well , he will continue his *examination* of the transatlantic connections that fuelled the slave trade .>\n",
      "<Context_185/examination.n The US ranks 37th in a World Health Organization *examination* of the world 's health care systems .>\n",
      "<Context_186/examination.n 40 Among studies that found differences in procedure use in sex-discordant pairings , these differences have been seen largely in sex-specific services such as mammography screening , 25 , 35 , 39 prostate examination , 39 and pelvic *examination* or Papanicolaou smear testing , 25 , 35 , 39 selected procedures that may have produced differences in use rates because of their sex-specific nature .>\n",
      "<Context_187/examination.n The photograph on the surface does not show a conflict or an irony , but with close *examination* , the punctum &#8212;the element which stands out and punctures the stadium &#8212;becomes apparent .>\n",
      "<Context_188/examination.n None *EXAMINATION* QUESTIONS , 1961-1965 Examination Questions , ca 1961-1965 , 30 cm ( c.1 , c.21 ) Examination question papers for various courses arranged alphabetically by subject and session .>\n",
      "<Context_189/examination.n Examination leave also includes the mornings of days in which examinations are held in the afternoon as well as the time spent travelling to and from the *examination* centre .>\n",
      "<Context_190/examination.n I was given cardiovascular tests , including treadmill stress tests and ultrasound *examinations* of my heart , but apparently , things weren&#194;&#146;t bad enough that I was singled out for consultation .>\n",
      "<Context_191/fear.v I *feared* only her car , and she was like a ghost , an apparition haunting the car , only a part of it , not a person .>\n",
      "<Context_192/fear.v \" she asked , already *fearing* a negative answer but impressed by the merit of his constructive reply .>\n",
      "<Context_193/fear.v He *fears* that she will die while he is gone .>\n",
      "<Context_194/fear.v When Esther *fears* to enter the court unsummoned , a capital offense unless the king holds out the golden sceptre , Mordecai says \" Think not with thyself that thou shalt escape in the king 's house , more than all the Jews .>\n",
      "<Context_195/fear.v Though the Act was well supported , it also aroused vehement opposition from those who *feared* it would promote the evils it was intended to remedy .>\n",
      "<Context_196/fear.v 6th February , 2004 - View article ... Extra Home Threat to Green belt The new targets published last week could force St Albans into sacrificing more Green Belt land than was first *feared* .>\n",
      "<Context_197/fear.v Muslim-Americans need to do this bit by bit , word by word , to show our fellow citizens that America has nothing to *fear* from Islam .>\n",
      "<Context_198/fear.v Many of those who founded the wargame publishing business *feared* that , with the anti-militarism caused by the Vietnam , and ( later ) with the adoption of the all-volunteer army , American society would become estranged from all things military , leaving ordinary citizens too ignorant to make meaningful democratic judgments where war is concerned .>\n",
      "<Context_199/fear.v Genetic engineering and human cloning are not to be *feared* but cherished , as they will liberate humanity from nature .>\n",
      "<Context_200/fear.v Nothing , I *fear* , I haven&#8217;t said already .>\n",
      "<Context_201/forget.v Do n't *forget* about the revolutionary exercise program and the lifestyle modification program. ) You will also learn , on the topic of diet : How to eliminate those crazy , irresistible cravings forever .>\n",
      "<Context_202/forget.v But Mr. SchickeleÂs own music has not been *forgotten* ; his eagerly-awaited Concerto for Viola and Orchestra will receive its world premiere with The Pasadena Symphony and Danielle Farina , viola .>\n",
      "<Context_203/forget.v Do n't *forget* to do the quick inventory and again tape it to the outside of the box .>\n",
      "<Context_204/forget.v Finally being super christian , I was reminded of the 2nd greatest commandment of all “You shall love your neighbour as yourself’” its easy to *forget* when you losing .>\n",
      "<Context_205/forget.v Sometimes you might be out of the office but want to know how your database is doing , sometimes you might be in vacation , sometimes you simply *forgot* to run the script ( we&#194;&#146;re humans ) ... How can you be notified with these details ?>\n",
      "<Context_206/forget.v One must not *forget* that the reason why the conflict has become difficult to handle over the years is because it has grown in complexity and become something of a family war .>\n",
      "<Context_207/forget.v Since the last issue of Britannia we have at last seen a bit of barrack life and all rumours about the issue of the ' Sennelager Star ' are being *forgotten* .>\n",
      "<Context_208/forget.v Someone from the event forwarded me this quote which I had *forgotten* .>\n",
      "<Context_209/forget.v Then to top it all off the docs *forgot* to enter the med rates so the oncall doc needed to be called which takes a long time .>\n",
      "<Context_210/forget.v Does he *forget* that it was his ministry that issued the final set of licences some three months prior to the collapse of Principal Trust ?>\n",
      "<Context_211/gall.n Galls indeed arise from the stinging of the plant tissues by the ovipositors of female gall wasps , and the egg laid in the plant tissues develops inside the gall into a grub , which eventually emerges full-grown and transformed into a mature *gall* wasp .>\n",
      "<Context_212/gall.n These include laparoscopic *gall* bladder surgery and reflux disease surgery , non-cardiac thoracoscopic chest surgery , and certain cardiotomy procedures such as mitral valve repair .>\n",
      "<Context_213/gall.n \" ( Adams , pp.196-9 ) What arrogance and *gall* it took to write those words and demand that they be spoken by Native tongues .>\n",
      "<Context_214/gall.n In the case of my *gall* bladder removal , I was out the next day .>\n",
      "<Context_215/gall.n Even *galls* that formed on their trunks were eaten .>\n",
      "<Context_216/gall.n Come to my woman 's breasts , And take my milk for *gall* , you murdering ministers , Wherever in your sightless substances You wait on nature 's mischief !>\n",
      "<Context_217/gall.n And the morans have the *gall* to ruin Beethoven&#146;s 6th in the process , too .>\n",
      "<Context_218/gall.n Etym : From the Gaelic name Dubhghall , from dubh \" black \" + *gall* \" stranger \" .>\n",
      "<Context_219/gall.n None *Galls* indeed arise from the stinging of the plant tissues by the ovipositors of female gall wasps , and the egg laid in the plant tissues develops inside the gall into a grub , which eventually emerges full-grown and transformed into a mature gall wasp .>\n",
      "<Context_220/gall.n In Boston Magazine 's glowing blurb on Via Matta , it had the extraordinary *gall* to say this : \" Via Matta has unquestionably found its niche with Boston 's it crowd .>\n",
      "<Context_221/grim.a \" What is the world to do in the face of these *grim* predictions ?>\n",
      "<Context_222/grim.a “He too can only watch in deepening despair as the *grim* work proceeds.&#8221; Looks more like resignation to me , but AudioVision is not interested in letting us make up our own minds. &#8220;Finally , the military police carry the crates away for disposal.&#8221; No , they just take them away .>\n",
      "<Context_223/grim.a Id rather go face down , fast , in a plate of chili at 76 than suffer the *grim* attenuations of mental decay and wander off this mortal plane at 78 .>\n",
      "<Context_224/grim.a Vincent van Gogh in 1880 was a 27-year-old failure : a despised and rejected clergyman in a *grim* backwater mining town in Belgium .>\n",
      "<Context_225/grim.a Hoarding and saving react with *grim* vengeance .>\n",
      "<Context_226/grim.a \" Once that *grim* reality had sunk in , Kubrick 's response was an extraordinary tribute to Sellers as an actor : \" We ca n't replace him with another actor , we 've got to get an authentic character from life , someone whose acting career is secondary-a real-life cowboy .>\n",
      "<Context_227/grim.a Their trip had been a *grim* struggle with wet pitches , friable rock and bad bolts : they had reached the 1979 limit , but failed to go further .>\n",
      "<Context_228/grim.a I 'm concerned that they 're so *grim* and angry .>\n",
      "<Context_229/grim.a \" That 's Lawrence Kaplan ' s *grim* verdict from Baghdad .>\n",
      "<Context_230/grim.a It started out looking pretty *grim* but we had pretty good rainfall in April and May .>\n",
      "<Context_231/lie.v \" Â \" 50 dollars \" , I *lie* .>\n",
      "<Context_232/lie.v But in spite of this truth , just as you in the position of aspirants and disciples know much about the Hierarchy , its life , aims and conditioning rules , so do I , a Master of the fifth degree , know much concerning what *lies* ahead of me ; I can therefore endeavor to make some small part of these essential truths clearer to those who can profit by them .>\n",
      "<Context_233/lie.v I *lie* down on my futon -bed with a tiny bean-filled pillow under my neck .>\n",
      "<Context_234/lie.v For example , suppose that on the return trip from Deneb to Earth the astronauts *lay* down Tube II rather than traveling back in Tube I , the first tube they produced .>\n",
      "<Context_235/lie.v What *lies* beneath the amphoras and the muck -- perhaps the ship 's wooden hull , tools , personal items and coins , which would help pinpoint the date of the sinking -- can only be learned by excavation .>\n",
      "<Context_236/lie.v \" \" You ca n't *lie* in front of the bulldozer indefinitely \" \" I 'm game ... \" \" Zaphod , you look good .>\n",
      "<Context_237/lie.v He went on farther , and in the great hall he saw the whole of the court lying asleep , and up by the throne *lay* the King and Queen .>\n",
      "<Context_238/lie.v Grabbed the blaster *lying* on the seat next to her and fired up at him .>\n",
      "<Context_239/lie.v Whether itÃ¢ÂÂs lying through omission , *lying* through misdirection , or outright lies , it&#195;&#162;&#194;&#128;&#194;&#153;s awfully hard to extract nuggets of truth from the noise .>\n",
      "<Context_240/lie.v You 're naked , lying in your bed surrounded by sex toys , with an empty bottle of lube and a videotape *lying* next to you .>\n",
      "<Context_241/nasty.a It is human nature to fight unfairly ; therefore , we need to think in advance and rehearse in advance how to fight fairly , so we wo n't get *nasty* when we get angry .>\n",
      "<Context_242/nasty.a He did n't say anything and kept smiling an insincere and *nasty* smile .>\n",
      "<Context_243/nasty.a The Mountain : \" Conditions are about to get *nasty* .>\n",
      "<Context_244/nasty.a And will probably stay *nasty* during the next administration , no matter who wins .>\n",
      "<Context_245/nasty.a The nasty party after all October 10 , leader : Iain Duncan Smith delivered a speech to the 2003 Tory party conference in Blackpool yesterday that was *nasty* , brutish and long .>\n",
      "<Context_246/nasty.a \" ( on playing Verdasco ) \" He 's *nasty* .>\n",
      "<Context_247/nasty.a Lewis Gilbert’s 1966 misogynistic rake’s progress always depended on the cheek , charm and chutzpah of the Kohl-eyed Caine’s iconic Cockney cocksman to take away the *nasty* taste in one&#8217;s mouth .>\n",
      "<Context_248/nasty.a I would like a big , *nasty* , mean , ugly automatic rifle or grenade launcher that I could fire at any car whose alarm blares repeatedly .>\n",
      "<Context_249/nasty.a A few years ago , when most monitors used 256 colours , it was important to use the Web Safe palette to avoid *nasty* dithering .>\n",
      "<Context_250/nasty.a These programs , called malware , can do *nasty* things like spy on you when you use your PC and allow hackers to access your hard drive .>\n",
      "<Context_251/nearly.r \" I 'm glad we made lots of money , though it *nearly* cost the two of you your sanity .>\n",
      "<Context_252/nearly.r In the 1997 elections , constitutional nationalism *nearly* lost out to republicanism .>\n",
      "<Context_253/nearly.r Fire Lookout Museum 123 W. Westview Spokane , WA 99218 ( 509)466-9171 email : rkresek@webtv.net INTRODUCTION During the summer of 2000 , the Inland Northwest United States experienced a wildfire season *nearly* unprecedented in America .>\n",
      "<Context_254/nearly.r HOUSTON , Texas ( CNN ) -- Human remains found in a field in Texas late Saturday are believed to be those of at least one of the seven astronauts who perished aboard space shuttle Columbia when it disintegrated *nearly* 40 miles above the Earth .>\n",
      "<Context_255/nearly.r Geographically , the West Bank , then under Jordanian rule and occupation , cut Israel *nearly* in half .>\n",
      "<Context_256/nearly.r I had n't *nearly* finished the work at hand .>\n",
      "<Context_257/nearly.r Comprised of thousands of small , independent units , the printing industry employs *nearly* 1 million in some 60,000-100,000 plants and accounts for somewhere in the neighborhood of 100 billion dollars in business every single year , while at the same time , contributing to toxic air emissions and solid and chemical waste problems on an ever-growing scale .>\n",
      "<Context_258/nearly.r In fact , according to his congressional biography , Murtha was on active duty for six years at most ( 1952-55 and 1966-67 ) ; the rest of the time , including some 16 of his *nearly* 32 years in the House , he was a reservist .>\n",
      "<Context_259/nearly.r Semantically , FDR COULD be the cause of the Great Depression if you think , as I do , that the recession wouldn’t have lasted *nearly* as long without all his taxes , price fixing , wage fixing , and regulations .>\n",
      "<Context_260/nearly.r In the preceding decade of political struggle , Ms. Bhutto was arrested on numerous occasions ; in all she spent *nearly* 6 years either in prison or under detention for her dedicated leadership of the then opposition Pakistan Peoples Party .>\n",
      "<Context_261/outdoor.a \" Our peak is early November , but it has gotten a little later as the years go by , \" said Dave Menke , the U. S. Fish and Wildlife Service 's Klamath Refuge Complex *outdoor* recreation specialist .>\n",
      "<Context_262/outdoor.a The goals for the camp include : 1 ) Outdoor experiences 2 ) Social integration ( English and Spanish speakers ) 3 ) Academic learning in the outdoors Students will plan and lead a variety of games and activities including , but not limited to : math lessons , art projects , games , and *outdoor* leadership/teambuilding initiatives .>\n",
      "<Context_263/outdoor.a None *Outdoor* Electrical Safety Check Tips For The Safe Outdoor Use Of Electricity ESFi Electrical Safety Foundation International Published as a public service by the Electrical Safety Foundation International in cooperation with the U.S. Consumer Product Safety Commission and the Canada Safety Council .>\n",
      "<Context_264/outdoor.a According to John Reichling of Camp , Dresser & McKee , an environmental engineering firm in Cambridge , Mass. , \" shelter in place \" also involves architectural changes such as widening hallways , enlarging rooms , and enclosing *outdoor* hallways .>\n",
      "<Context_265/outdoor.a A bridge takes one over into the *outdoor* space that is the heart of the home , the nucleus , held on each side by the three structures that surround it .>\n",
      "<Context_266/outdoor.a Work : In a Landscape protected area , making the birds little wooden houses , springs and little rivers cleaning , *outdoor* environmental work .>\n",
      "<Context_267/outdoor.a IATSE donated free labor and an *outdoor* sound system .>\n",
      "<Context_268/outdoor.a This is about as big as most finecky fine-art photographers require , and even *outdoor* billboards are routinely made from files with less resolution that this .>\n",
      "<Context_269/outdoor.a Active children and adults , and people with respiratory disease , such as asthma , should avoid prolonged outdoor exertion ; everyone else , especially children , should limit prolonged *outdoor* exertion .>\n",
      "<Context_270/outdoor.a With the growing demand for these fine garden furnishings , they found it necessary to dedicate a portion of their business to *outdoor* living and patio furnishings .>\n",
      "<Context_271/reasonable.a Due to China 's economic reliance on trade , balance of payments should be the main factor for judging whether the yuan exchange rate is *reasonable* .>\n",
      "<Context_272/reasonable.a Copyright law already addressed the issue in a much more *reasonable* manner .>\n",
      "<Context_273/reasonable.a \" What we require now is the co-operation from the Federal Government to provide a flow of mortgage money through CMHC at *reasonable* interest rates and to encourage the conventional loans to be channelled into smaller units so that we may have the opportunity of the best housing and building programme in Canada in 1971 .>\n",
      "<Context_274/reasonable.a For *reasonable* people , sure that 'll suffice .>\n",
      "<Context_275/reasonable.a Your objective should be to negotiate a contract type and price ( or estimated fee and cost ) that will result in *reasonable* contractor risk and provide the contractor with the greatest incentive for efficient and economical contract performance .>\n",
      "<Context_276/reasonable.a And if no exact & safe equilibrium can be introduced , it is more *reasonable* that a preponderating weight shd. be allowed to the greater interest than to the lesser .>\n",
      "<Context_277/reasonable.a Besides overseeing the operation of PIPEDA and dealing with complaints , I can conduct audits into organizations ' personal information-handling practices , if we have *reasonable* grounds .>\n",
      "<Context_278/reasonable.a The matter of the further evidence may then be heard when the other party has had *reasonable* opportunity to prepare submissions on the matter .>\n",
      "<Context_279/reasonable.a This will allow state-licensed health-care providers to utilize safe , non-FDA approved , alternative therapies that have a *reasonable* expectation of therapeutic gain if the patient has been fully informed about the treatment .>\n",
      "<Context_280/reasonable.a ( 2 ) In a civil action under subsection ( a ) of this section , the court , in its discretion , may allow the prevailing party , other than the United States , a *reasonable* attorney 's fee and costs .>\n",
      "<Context_281/rough.a But I think we can already see from this and other defenses coming from administration officials that the White House 's line on this is filled with clear distortions and misstatements of fact -- most of which are easily identifiable by people who have even a *rough* understanding of the timing and issues involved .>\n",
      "<Context_282/rough.a On right there is a steep fall of 10ft. to *rough* grass between 4th and adjacent fairway .>\n",
      "<Context_283/rough.a The surface of the keyboard is a *rough* metal ( a wrought iron feel , if you will ) , and two black wooden braces support the frame on either side .>\n",
      "<Context_284/rough.a A very *rough* way of gauging your so-called preferred weight is to use the Body Mass Index ( BMI ) .>\n",
      "<Context_285/rough.a NOTE : For the aviation and MRF models , the lifted index field is not broadcast so the showalter index ( a *rough* equivalent ) is plotted instead .>\n",
      "<Context_286/rough.a None *Rough* estimates show that there are between 75,000 and 100,000 professional speakers in the U.S. alone and when you add trainers the number goes up into the millions .>\n",
      "<Context_287/rough.a He was apparently given a *rough* ride by the interviewer , Cathal MacCoille .>\n",
      "<Context_288/rough.a Next , the piece went to the \" smoother \" , who went back over all the *rough* cuts with stone wheels called \" craighleiths .>\n",
      "<Context_289/rough.a It was a very poor area and Stanway Street was very overcrowded and *rough* .>\n",
      "<Context_290/rough.a Col. Berry led again so it was a *rough* job .>\n",
      "<Context_291/run.v \" While Washington 's attention focuses on key congressional races and contests for governor , ballot measures have a direct impact on how U.S. society is *run* and often presage future national political debates .>\n",
      "<Context_292/run.v No one becomes a teacher until after interning in a *running* school .>\n",
      "<Context_293/run.v It ran six to seven pages single spaced ; the calculation for determining how much the farmers would get paid alone *ran* several pages .>\n",
      "<Context_294/run.v Chapters from this book by Paul Collins have *run* in McSweeney 's Quarterly Concern .>\n",
      "<Context_295/run.v \" DonÂt be afraid to bring in a professional negotiator , someone to *run* a meeting , anyone you need to work through the issues,&#194;&#148; Johnson advises .>\n",
      "<Context_296/run.v Anyway here are some static pictures of the boat - it is driven by a brushless motor driving a prop - but when it 's *running* you ca n't see it .>\n",
      "<Context_297/run.v Last year , for example , we *ran* 2,659 elections in a median time of 40 days. And , 92.5 % of these elections were run within 56 days. This is quite a remarkable record and we are very proud of it .>\n",
      "<Context_298/run.v This is an excellent and important discussion because it *runs* counter to most of the stock talk of the past generation .>\n",
      "<Context_299/run.v Rumor has it that Apple is just B4 offering a cheap ( $ 500 ) computer that *runs* the bullet-proof OS-X operating system .>\n",
      "<Context_300/run.v \" Why do you *run* from me ?>\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.argv=['lexsub_xml.py', 'lexsub_trial.xml',]\n",
    "\n",
    "for context in read_lexsub_xml(sys.argv[1]):\n",
    "      print(context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnh2HPD1V1rg"
   },
   "source": [
    "**Import lexsub_main.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Arq2T3vtVIwX"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys\n",
    "\n",
    "# from lexsub_xml import read_lexsub_xml\n",
    "# from lexsub_xml import Context \n",
    "\n",
    "# suggested imports \n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "\n",
    "\n",
    "\n",
    "import gensim\n",
    "import transformers \n",
    "\n",
    "from typing import List\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "GOEbxmWjV9x9"
   },
   "outputs": [],
   "source": [
    "def tokenize(s): \n",
    "    \"\"\"\n",
    "    a naive tokenizer that splits on punctuation and whitespaces.  \n",
    "    \"\"\"\n",
    "    s = \"\".join(\" \" if x in string.punctuation else x for x in s.lower())    \n",
    "    return s.split() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4wnuZ2VWyBV"
   },
   "source": [
    "**Part 1: Candidate Synonyms from WordNet (18 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "aMBYNN9ZWBkN"
   },
   "outputs": [],
   "source": [
    "def get_candidates(lemma, pos) -> List[str]:\n",
    "    # Part 1    \n",
    "    possible_synonyms = []\n",
    "    for synset in wn.synsets(lemma, pos):\n",
    "        for synonym in synset.lemmas():\n",
    "            if synonym.name() != lemma: \n",
    "              if \"_\" not in synonym.name():\n",
    "                  possible_synonyms.append(synonym.name())\n",
    "              elif \"_\" in synonym.name():   \n",
    "                  possible_synonyms.append(synonym.name().replace('_',' '))\n",
    "    possible_synonyms = list(set(possible_synonyms)) #remove duplicate\n",
    "  \n",
    "    return possible_synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "d6feH354WI1V"
   },
   "outputs": [],
   "source": [
    "def smurf_predictor(context : Context) -> str:\n",
    "    \"\"\"\n",
    "    suggest 'smurf' as a substitute for all words.\n",
    "    \"\"\"\n",
    "    return 'smurf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6KfDysIGWLYE",
    "outputId": "3006f5f2-0cc4-4e8c-e64e-353496c8a0b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bright.a 1 :: smurf\n",
      "bright.a 2 :: smurf\n",
      "bright.a 3 :: smurf\n",
      "bright.a 4 :: smurf\n",
      "bright.a 5 :: smurf\n",
      "bright.a 6 :: smurf\n",
      "bright.a 7 :: smurf\n",
      "bright.a 8 :: smurf\n",
      "bright.a 9 :: smurf\n",
      "bright.a 10 :: smurf\n",
      "film.n 11 :: smurf\n",
      "film.n 12 :: smurf\n",
      "film.n 13 :: smurf\n",
      "film.n 14 :: smurf\n",
      "film.n 15 :: smurf\n",
      "film.n 16 :: smurf\n",
      "film.n 17 :: smurf\n",
      "film.n 18 :: smurf\n",
      "film.n 19 :: smurf\n",
      "film.n 20 :: smurf\n",
      "take.v 21 :: smurf\n",
      "take.v 22 :: smurf\n",
      "take.v 23 :: smurf\n",
      "take.v 24 :: smurf\n",
      "take.v 25 :: smurf\n",
      "take.v 26 :: smurf\n",
      "take.v 27 :: smurf\n",
      "take.v 28 :: smurf\n",
      "take.v 29 :: smurf\n",
      "take.v 30 :: smurf\n",
      "tight.r 31 :: smurf\n",
      "tight.r 32 :: smurf\n",
      "tight.r 33 :: smurf\n",
      "tight.r 34 :: smurf\n",
      "tight.r 35 :: smurf\n",
      "tight.r 36 :: smurf\n",
      "tight.r 37 :: smurf\n",
      "tight.r 38 :: smurf\n",
      "tight.r 39 :: smurf\n",
      "tight.r 40 :: smurf\n",
      "bar.n 41 :: smurf\n",
      "bar.n 42 :: smurf\n",
      "bar.n 43 :: smurf\n",
      "bar.n 44 :: smurf\n",
      "bar.n 45 :: smurf\n",
      "bar.n 46 :: smurf\n",
      "bar.n 47 :: smurf\n",
      "bar.n 48 :: smurf\n",
      "bar.n 49 :: smurf\n",
      "bar.v 50 :: smurf\n",
      "cross.n 51 :: smurf\n",
      "cross.n 52 :: smurf\n",
      "cross.n 53 :: smurf\n",
      "cross.n 54 :: smurf\n",
      "cross.n 55 :: smurf\n",
      "cross.n 56 :: smurf\n",
      "cross.n 57 :: smurf\n",
      "cross.n 58 :: smurf\n",
      "cross.n 59 :: smurf\n",
      "cross.a 60 :: smurf\n",
      "finally.r 61 :: smurf\n",
      "finally.r 62 :: smurf\n",
      "finally.r 63 :: smurf\n",
      "finally.r 64 :: smurf\n",
      "finally.r 65 :: smurf\n",
      "finally.r 66 :: smurf\n",
      "finally.r 67 :: smurf\n",
      "finally.r 68 :: smurf\n",
      "finally.r 69 :: smurf\n",
      "finally.r 70 :: smurf\n",
      "find.v 71 :: smurf\n",
      "find.v 72 :: smurf\n",
      "find.v 73 :: smurf\n",
      "find.v 74 :: smurf\n",
      "find.v 75 :: smurf\n",
      "find.v 76 :: smurf\n",
      "find.v 77 :: smurf\n",
      "find.v 78 :: smurf\n",
      "find.v 79 :: smurf\n",
      "find.v 80 :: smurf\n",
      "fix.v 81 :: smurf\n",
      "fix.v 82 :: smurf\n",
      "fix.v 83 :: smurf\n",
      "fix.v 84 :: smurf\n",
      "fix.v 85 :: smurf\n",
      "fix.v 86 :: smurf\n",
      "fix.v 87 :: smurf\n",
      "fix.v 88 :: smurf\n",
      "fix.v 89 :: smurf\n",
      "fix.v 90 :: smurf\n",
      "manage.v 91 :: smurf\n",
      "manage.v 92 :: smurf\n",
      "manage.v 93 :: smurf\n",
      "manage.v 94 :: smurf\n",
      "manage.v 95 :: smurf\n",
      "manage.v 96 :: smurf\n",
      "manage.v 97 :: smurf\n",
      "manage.v 98 :: smurf\n",
      "manage.v 99 :: smurf\n",
      "manage.v 100 :: smurf\n",
      "neat.a 101 :: smurf\n",
      "neat.a 102 :: smurf\n",
      "neat.a 103 :: smurf\n",
      "neat.a 104 :: smurf\n",
      "neat.a 105 :: smurf\n",
      "neat.a 106 :: smurf\n",
      "neat.a 107 :: smurf\n",
      "neat.a 108 :: smurf\n",
      "neat.a 109 :: smurf\n",
      "neat.a 110 :: smurf\n",
      "rich.a 111 :: smurf\n",
      "rich.a 112 :: smurf\n",
      "rich.a 113 :: smurf\n",
      "rich.a 114 :: smurf\n",
      "rich.a 115 :: smurf\n",
      "rich.a 116 :: smurf\n",
      "rich.a 117 :: smurf\n",
      "rich.a 118 :: smurf\n",
      "rich.a 119 :: smurf\n",
      "rich.a 120 :: smurf\n",
      "severely.r 121 :: smurf\n",
      "severely.r 122 :: smurf\n",
      "severely.r 123 :: smurf\n",
      "severely.r 124 :: smurf\n",
      "severely.r 125 :: smurf\n",
      "severely.r 126 :: smurf\n",
      "severely.r 127 :: smurf\n",
      "severely.r 128 :: smurf\n",
      "severely.r 129 :: smurf\n",
      "severely.r 130 :: smurf\n",
      "stand.v 131 :: smurf\n",
      "stand.v 132 :: smurf\n",
      "stand.v 133 :: smurf\n",
      "stand.v 134 :: smurf\n",
      "stand.v 135 :: smurf\n",
      "stand.v 136 :: smurf\n",
      "stand.n 137 :: smurf\n",
      "stand.n 138 :: smurf\n",
      "stand.n 139 :: smurf\n",
      "stand.n 140 :: smurf\n",
      "well.r 141 :: smurf\n",
      "well.r 142 :: smurf\n",
      "well.r 143 :: smurf\n",
      "well.r 144 :: smurf\n",
      "well.r 145 :: smurf\n",
      "well.r 146 :: smurf\n",
      "well.r 147 :: smurf\n",
      "well.r 148 :: smurf\n",
      "well.r 149 :: smurf\n",
      "well.r 150 :: smurf\n",
      "wild.a 151 :: smurf\n",
      "wild.a 152 :: smurf\n",
      "wild.a 153 :: smurf\n",
      "wild.a 154 :: smurf\n",
      "wild.a 155 :: smurf\n",
      "wild.a 156 :: smurf\n",
      "wild.a 157 :: smurf\n",
      "wild.a 158 :: smurf\n",
      "wild.a 159 :: smurf\n",
      "wild.n 160 :: smurf\n",
      "can.n 161 :: smurf\n",
      "can.n 162 :: smurf\n",
      "can.n 163 :: smurf\n",
      "can.n 164 :: smurf\n",
      "can.n 165 :: smurf\n",
      "can.n 166 :: smurf\n",
      "can.n 167 :: smurf\n",
      "can.n 168 :: smurf\n",
      "can.n 169 :: smurf\n",
      "can.n 170 :: smurf\n",
      "dark.n 171 :: smurf\n",
      "dark.n 172 :: smurf\n",
      "dark.n 173 :: smurf\n",
      "dark.n 174 :: smurf\n",
      "dark.n 175 :: smurf\n",
      "dark.n 176 :: smurf\n",
      "dark.n 177 :: smurf\n",
      "dark.n 178 :: smurf\n",
      "dark.n 179 :: smurf\n",
      "dark.n 180 :: smurf\n",
      "examination.n 181 :: smurf\n",
      "examination.n 182 :: smurf\n",
      "examination.n 183 :: smurf\n",
      "examination.n 184 :: smurf\n",
      "examination.n 185 :: smurf\n",
      "examination.n 186 :: smurf\n",
      "examination.n 187 :: smurf\n",
      "examination.n 188 :: smurf\n",
      "examination.n 189 :: smurf\n",
      "examination.n 190 :: smurf\n",
      "fear.v 191 :: smurf\n",
      "fear.v 192 :: smurf\n",
      "fear.v 193 :: smurf\n",
      "fear.v 194 :: smurf\n",
      "fear.v 195 :: smurf\n",
      "fear.v 196 :: smurf\n",
      "fear.v 197 :: smurf\n",
      "fear.v 198 :: smurf\n",
      "fear.v 199 :: smurf\n",
      "fear.v 200 :: smurf\n",
      "forget.v 201 :: smurf\n",
      "forget.v 202 :: smurf\n",
      "forget.v 203 :: smurf\n",
      "forget.v 204 :: smurf\n",
      "forget.v 205 :: smurf\n",
      "forget.v 206 :: smurf\n",
      "forget.v 207 :: smurf\n",
      "forget.v 208 :: smurf\n",
      "forget.v 209 :: smurf\n",
      "forget.v 210 :: smurf\n",
      "gall.n 211 :: smurf\n",
      "gall.n 212 :: smurf\n",
      "gall.n 213 :: smurf\n",
      "gall.n 214 :: smurf\n",
      "gall.n 215 :: smurf\n",
      "gall.n 216 :: smurf\n",
      "gall.n 217 :: smurf\n",
      "gall.n 218 :: smurf\n",
      "gall.n 219 :: smurf\n",
      "gall.n 220 :: smurf\n",
      "grim.a 221 :: smurf\n",
      "grim.a 222 :: smurf\n",
      "grim.a 223 :: smurf\n",
      "grim.a 224 :: smurf\n",
      "grim.a 225 :: smurf\n",
      "grim.a 226 :: smurf\n",
      "grim.a 227 :: smurf\n",
      "grim.a 228 :: smurf\n",
      "grim.a 229 :: smurf\n",
      "grim.a 230 :: smurf\n",
      "lie.v 231 :: smurf\n",
      "lie.v 232 :: smurf\n",
      "lie.v 233 :: smurf\n",
      "lie.v 234 :: smurf\n",
      "lie.v 235 :: smurf\n",
      "lie.v 236 :: smurf\n",
      "lie.v 237 :: smurf\n",
      "lie.v 238 :: smurf\n",
      "lie.v 239 :: smurf\n",
      "lie.v 240 :: smurf\n",
      "nasty.a 241 :: smurf\n",
      "nasty.a 242 :: smurf\n",
      "nasty.a 243 :: smurf\n",
      "nasty.a 244 :: smurf\n",
      "nasty.a 245 :: smurf\n",
      "nasty.a 246 :: smurf\n",
      "nasty.a 247 :: smurf\n",
      "nasty.a 248 :: smurf\n",
      "nasty.a 249 :: smurf\n",
      "nasty.a 250 :: smurf\n",
      "nearly.r 251 :: smurf\n",
      "nearly.r 252 :: smurf\n",
      "nearly.r 253 :: smurf\n",
      "nearly.r 254 :: smurf\n",
      "nearly.r 255 :: smurf\n",
      "nearly.r 256 :: smurf\n",
      "nearly.r 257 :: smurf\n",
      "nearly.r 258 :: smurf\n",
      "nearly.r 259 :: smurf\n",
      "nearly.r 260 :: smurf\n",
      "outdoor.a 261 :: smurf\n",
      "outdoor.a 262 :: smurf\n",
      "outdoor.a 263 :: smurf\n",
      "outdoor.a 264 :: smurf\n",
      "outdoor.a 265 :: smurf\n",
      "outdoor.a 266 :: smurf\n",
      "outdoor.a 267 :: smurf\n",
      "outdoor.a 268 :: smurf\n",
      "outdoor.a 269 :: smurf\n",
      "outdoor.a 270 :: smurf\n",
      "reasonable.a 271 :: smurf\n",
      "reasonable.a 272 :: smurf\n",
      "reasonable.a 273 :: smurf\n",
      "reasonable.a 274 :: smurf\n",
      "reasonable.a 275 :: smurf\n",
      "reasonable.a 276 :: smurf\n",
      "reasonable.a 277 :: smurf\n",
      "reasonable.a 278 :: smurf\n",
      "reasonable.a 279 :: smurf\n",
      "reasonable.a 280 :: smurf\n",
      "rough.a 281 :: smurf\n",
      "rough.a 282 :: smurf\n",
      "rough.a 283 :: smurf\n",
      "rough.a 284 :: smurf\n",
      "rough.a 285 :: smurf\n",
      "rough.a 286 :: smurf\n",
      "rough.a 287 :: smurf\n",
      "rough.a 288 :: smurf\n",
      "rough.a 289 :: smurf\n",
      "rough.a 290 :: smurf\n",
      "run.v 291 :: smurf\n",
      "run.v 292 :: smurf\n",
      "run.v 293 :: smurf\n",
      "run.v 294 :: smurf\n",
      "run.v 295 :: smurf\n",
      "run.v 296 :: smurf\n",
      "run.v 297 :: smurf\n",
      "run.v 298 :: smurf\n",
      "run.v 299 :: smurf\n",
      "run.v 300 :: smurf\n"
     ]
    }
   ],
   "source": [
    "sys.argv=['lexsub_xml.py', 'lexsub_trial.xml',]\n",
    "for context in read_lexsub_xml(sys.argv[1]):\n",
    "        #print(context)  # useful for debugging\n",
    "        prediction = smurf_predictor(context) \n",
    "        print(\"{}.{} {} :: {}\".format(context.lemma, context.pos, context.cid, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ca5-144UArzj"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "# redirect stdout to a buffer\n",
    "stdout_buffer = StringIO()\n",
    "sys.stdout = stdout_buffer\n",
    "\n",
    "# run lexsub_main.py script with lexsub_trial.xml input\n",
    "sys.argv = ['lexsub_xml.py', 'lexsub_trial.xml']\n",
    "\n",
    "# read lexsub_trial.xml file and apply smurf_predictor function to each context\n",
    "for context in read_lexsub_xml(sys.argv[1]):\n",
    "    prediction = smurf_predictor(context) \n",
    "    print(\"{}.{} {} :: {}\".format(context.lemma, context.pos, context.cid, prediction))\n",
    "\n",
    "# redirect stdout back to the console\n",
    "sys.stdout = sys.__stdout__\n",
    "\n",
    "# save output to smurf.predict file\n",
    "with open('smurf.predict', 'w') as f:\n",
    "  f.write(stdout_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxBOT7Pe3UrA"
   },
   "source": [
    "**perl score.pl smurf.predict gold.trial**\n",
    "\n",
    "Total = 298, attempted = 298\n",
    "\n",
    "precision = 0.000, recall = 0.000\n",
    "\n",
    "Total with mode 206 attempted 206\n",
    "\n",
    "precision = 0.000, recall = 0.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xc_crgArWcTP",
    "outputId": "1d0a19b2-3f04-446d-d67e-065bbb985c93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dumb',\n",
       " 'ho-hum',\n",
       " 'tiresome',\n",
       " 'wearisome',\n",
       " 'irksome',\n",
       " 'dull',\n",
       " 'dim',\n",
       " 'boring',\n",
       " 'sluggish',\n",
       " 'tedious',\n",
       " 'obtuse',\n",
       " 'dense',\n",
       " 'deadening']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test part 1\n",
    "get_candidates('slow','a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnaZ-w9AZnGs"
   },
   "source": [
    "**Part 2: WordNet Frequency Baseline (18 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "3z4rOLVtckT5"
   },
   "outputs": [],
   "source": [
    "def wn_frequency_predictor(context : Context) -> str:\n",
    "    # part 2\n",
    "    word_dict = {}\n",
    "    for lemma in wn.lemmas(context.lemma, pos=context.pos):\n",
    "        for related_lemma in lemma.synset().lemmas():\n",
    "            if related_lemma.name().lower() != context.lemma:\n",
    "                word_dict[related_lemma.name().lower().replace('_',' ')] = word_dict.get(related_lemma.name().lower().replace('_',' '), 0) + related_lemma.count()\n",
    "     \n",
    "    return max(word_dict, key=word_dict.get) if len(word_dict) !=0 else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "NIayODuwaG3b",
    "outputId": "bfa48bd2-b361-41c2-a5fb-468083935b4a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'operate'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test for part 2\n",
    "print(context.lemma)\n",
    "print(context.pos)\n",
    "wn_frequency_predictor(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "9fJVDBbY_KsR"
   },
   "outputs": [],
   "source": [
    "# sys.argv=['lexsub_xml.py', 'lexsub_trial.xml',]\n",
    "# for context in read_lexsub_xml(sys.argv[1]):\n",
    "#         #print(context)  # useful for debugging\n",
    "#         prediction = wn_frequency_predictor(context) \n",
    "#         print(\"{}.{} {} :: {}\".format(context.lemma, context.pos, context.cid, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "6aAO3dIuG6ND"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "# redirect stdout to a buffer\n",
    "stdout_buffer = StringIO()\n",
    "sys.stdout = stdout_buffer\n",
    "\n",
    "# run lexsub_main.py script with lexsub_trial.xml input\n",
    "sys.argv = ['lexsub_xml.py', 'lexsub_trial.xml']\n",
    "\n",
    "# read lexsub_trial.xml file and apply smurf_predictor function to each context\n",
    "for context in read_lexsub_xml(sys.argv[1]):\n",
    "    prediction = wn_frequency_predictor(context) \n",
    "    print(\"{}.{} {} :: {}\".format(context.lemma, context.pos, context.cid, prediction))\n",
    "\n",
    "# redirect stdout back to the console\n",
    "sys.stdout = sys.__stdout__\n",
    "\n",
    "# save output to smurf.predict file\n",
    "with open('p2_wn_frequency.predict', 'w') as f:\n",
    "  f.write(stdout_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mJqxG863Qdm"
   },
   "source": [
    "**perl score.pl p2_wn_frequency.predict gold.trial**\n",
    "\n",
    "Total = 298, attempted = 298\n",
    "\n",
    "precision = 0.098, recall = 0.098\n",
    "\n",
    "Total with mode 206 attempted 206\n",
    "\n",
    "precision = 0.136, recall = 0.136"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jX-EASzhghjn"
   },
   "source": [
    "**Part 3: Simple Lesk Algorithm (18 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "rrgnPc34Mzo6"
   },
   "outputs": [],
   "source": [
    "def wn_simple_lesk_predictor(context: Context) -> str:\n",
    "    # part 3\n",
    "    stopwords_set = set(stopwords.words('english'))\n",
    "    leftright = [x.lower() for x in context.left_context + context.right_context]\n",
    "    leftright_clear = []\n",
    "    i = 0\n",
    "    while i < len(leftright):\n",
    "        if leftright[i] not in stopwords_set:\n",
    "            leftright_clear.append(leftright[i])\n",
    "        i += 1\n",
    "    \n",
    "    max_score = 0\n",
    "    result = None\n",
    "    synlist = set()\n",
    "    \n",
    "\n",
    "    for l1 in wn.lemmas(context.lemma, pos=context.pos):\n",
    "        overlap = set()\n",
    "        score = 0\n",
    "        syn = l1.synset()\n",
    "        \n",
    "        # Get all example and definition sentences\n",
    "        df = syn.examples()[:]\n",
    "        df.append(syn.definition())\n",
    "        for hyper in syn.hypernyms():\n",
    "            df.append(hyper.definition())\n",
    "            df += hyper.examples()\n",
    "        \n",
    "        \n",
    "        for sentence in df:\n",
    "            synlist |= set(tokenize(sentence.lower()))\n",
    "        \n",
    "        for word in synlist:\n",
    "            if word in leftright_clear and word not in overlap:\n",
    "                overlap.add(word)\n",
    " \n",
    "        for lem in syn.lemmas():\n",
    "            if lem.name().lower() != context.lemma:\n",
    "                score = 1000*len(overlap) + 100*l1.count() + lem.count()\n",
    "                if score >= max_score:\n",
    "                    max_score = score\n",
    "                    result = lem.name()\n",
    "                    result = result.replace('_', ' ')\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "QnLfKYOZHFVE",
    "outputId": "1c169e90-7b1b-42f9-9998-2c437ed5b83c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'run away'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test part 3 \n",
    "print(context.lemma)\n",
    "print(context.pos)\n",
    "wn_simple_lesk_predictor(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "0NG0gcf4BPdn"
   },
   "outputs": [],
   "source": [
    "# sys.argv=['lexsub_xml.py', 'lexsub_trial.xml',]\n",
    "# for context in read_lexsub_xml(sys.argv[1]):\n",
    "#         #print(context)  # useful for debugging\n",
    "#         prediction = wn_simple_lesk_predictor(context) \n",
    "#         print(\"{}.{} {} :: {}\".format(context.lemma, context.pos, context.cid, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "IsdnPqpRJDOu"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "# redirect stdout to a buffer\n",
    "stdout_buffer = StringIO()\n",
    "sys.stdout = stdout_buffer\n",
    "\n",
    "# run lexsub_main.py script with lexsub_trial.xml input\n",
    "sys.argv = ['lexsub_xml.py', 'lexsub_trial.xml']\n",
    "\n",
    "# read lexsub_trial.xml file and apply smurf_predictor function to each context\n",
    "for context in read_lexsub_xml(sys.argv[1]):\n",
    "    prediction = wn_simple_lesk_predictor(context) \n",
    "    print(\"{}.{} {} :: {}\".format(context.lemma, context.pos, context.cid, prediction))\n",
    "\n",
    "# redirect stdout back to the console\n",
    "sys.stdout = sys.__stdout__\n",
    "\n",
    "# save output to smurf.predict file\n",
    "with open('p3_wn_simple_lesk.predict', 'w') as f:\n",
    "  f.write(stdout_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oAguQS63MTZ"
   },
   "source": [
    "**perl score.pl p3_wn_simple_lesk.predict gold.trial** \n",
    "\n",
    "Total = 298, attempted = 298\n",
    "\n",
    "precision = 0.097, recall = 0.097\n",
    "\n",
    "Total with mode 206 attempted 206\n",
    "\n",
    "precision = 0.136, recall = 0.136"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfPla6xdDJ6C"
   },
   "source": [
    "**Part 4: Most Similar Synonym (18 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "o6-uOuXLDPA5"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Word2VecSubst(object):\n",
    "        \n",
    "    def __init__(self, filename):\n",
    "        self.model = gensim.models.KeyedVectors.load_word2vec_format(filename, binary=True)    \n",
    "\n",
    "    def predict_nearest(self,context : Context) -> str:\n",
    "        # replace for part 4         \n",
    "        candidates = get_candidates(context.lemma, context.pos)\n",
    "        max_score = -1\n",
    "        result = None\n",
    "        for candidate in candidates:\n",
    "            try:\n",
    "                score = self.model.similarity(context.lemma, candidate)\n",
    "                if score > max_score:\n",
    "                    max_score = score\n",
    "                    result = candidate\n",
    "            except KeyError:\n",
    "                continue\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "7BXbmWmWl4xZ"
   },
   "outputs": [],
   "source": [
    "# sys.argv = ['lexsub_xml.py', 'lexsub_trial.xml']\n",
    "# W2VMODEL_FILENAME = 'GoogleNews-vectors-negative300.bin.gz'\n",
    "# predictor = Word2VecSubst(W2VMODEL_FILENAME)\n",
    "\n",
    "# # read lexsub_trial.xml file and apply smurf_predictor function to each context\n",
    "# for context in read_lexsub_xml(sys.argv[1]):\n",
    "#     prediction = predictor.predict_nearest(context) \n",
    "#     print(\"{}.{} {} :: {}\".format(context.lemma, context.pos, context.cid, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Lit6RhDOl5TP"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "# redirect stdout to a buffer\n",
    "stdout_buffer = StringIO()\n",
    "sys.stdout = stdout_buffer\n",
    "\n",
    "# run lexsub_main.py script with lexsub_trial.xml input\n",
    "sys.argv = ['lexsub_xml.py', 'lexsub_trial.xml']\n",
    "W2VMODEL_FILENAME = 'GoogleNews-vectors-negative300.bin.gz'\n",
    "w2v_predictor = Word2VecSubst(W2VMODEL_FILENAME)\n",
    "\n",
    "# read lexsub_trial.xml file and apply smurf_predictor function to each context\n",
    "for context in read_lexsub_xml(sys.argv[1]):\n",
    "    prediction = w2v_predictor.predict_nearest(context) \n",
    "    print(\"{}.{} {} :: {}\".format(context.lemma, context.pos, context.cid, prediction))\n",
    "\n",
    "# redirect stdout back to the console\n",
    "sys.stdout = sys.__stdout__\n",
    "\n",
    "# save output to smurf.predict file\n",
    "with open('p4_w2v.predict', 'w') as f:\n",
    "  f.write(stdout_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9HGlHKO3Hk1"
   },
   "source": [
    "**perl score.pl p4_w2v.predict gold.trial**\n",
    "\n",
    "Total = 298, attempted = 298\n",
    "\n",
    "precision = 0.115, recall = 0.115\n",
    "\n",
    "Total with mode 206 attempted 206\n",
    "\n",
    "precision = 0.170, recall = 0.170"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cerX0e_lEcuq"
   },
   "source": [
    "**Part 5: Using BERT's masked language model (18 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "LEq7cfSZEUgG"
   },
   "outputs": [],
   "source": [
    "\n",
    "class BertPredictor(object):\n",
    "\n",
    "    def __init__(self): \n",
    "        self.tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        self.model = transformers.TFDistilBertForMaskedLM.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    def predict(self, context : Context) -> str:\n",
    "        # replace for part 5\n",
    "        candidates = get_candidates(context.lemma, context.pos)\n",
    "        inputlist = context.left_context[:] + ['[MASK]'] + context.right_context[:]\n",
    "        input_toks = self.tokenizer.encode(inputlist)\n",
    "        input_mat = np.array(input_toks).reshape((1,-1))\n",
    "        outputs = self.model.predict(input_mat, verbose=None)\n",
    "        predictions = outputs[0]\n",
    "        best_words = np.argsort(predictions[0][len(self.tokenizer.encode(context.left_context))-1])[::-1]\n",
    "        wordcand = self.tokenizer.convert_ids_to_tokens(best_words)\n",
    "        for word in wordcand:\n",
    "            if word in candidates:\n",
    "                return word\n",
    "        return wordcand[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "8jFoIveuYMw4"
   },
   "outputs": [],
   "source": [
    "# sys.argv = ['lexsub_xml.py', 'lexsub_trial.xml']\n",
    "# predictor = BertPredictor()\n",
    "\n",
    "# # read lexsub_trial.xml file and apply smurf_predictor function to each context\n",
    "# for context in read_lexsub_xml(sys.argv[1]):\n",
    "#     prediction = predictor.predict(context) \n",
    "#     print(\"{}.{} {} :: {}\".format(context.lemma, context.pos, context.cid, prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254,
     "referenced_widgets": [
      "69112408bb6d46fbbe9d950fca61784b",
      "ad9ffc2251f84964a2189cf609122245",
      "30b46cdf9f0f4202bdc37151d84f4d05",
      "5fe8fda641f84b2ebd4e31eeae816c23",
      "ebe52d425b7143d980da5b3eb3c36e50",
      "d59f3d64647a44fa824fdcf971a33de8",
      "48058f94ee934e7d82cb1f023a0d30e7",
      "bfef250ce1fd487e8a74988e2be0bc3c",
      "308468a23e3d4216bd86d3955ecfb0bc",
      "b134205696fd40429c728af71dfa773c",
      "cb48ce867afc485483a5d3ad68887585",
      "c2a0baef32724caa9ea3c48048c39f70",
      "9c6d381826674cdfa0bdae5624abb881",
      "4a9e62f3126541fb85dfd0c0e051a926",
      "bccc262cd49f4e3ab2a04c9c2dbec77d",
      "823d62fffaea47d98833a8840e92c834",
      "9412d2c6e1004b33a5a080aab769deac",
      "0ad870277b7a44c7ac5b2b7153490556",
      "684e44e1aa9c4278b98831f81e581f83",
      "345f94b167a04a42bd1911a85d0451be",
      "3ce388044a5e4cf688478b6940528dc5",
      "1e1aa05bfa554c279be1e75639a45568",
      "af18b18e70e240e786b128291ab95488",
      "4962e3fcde58489599821123acaed1e6",
      "c840aebd8bb348549cfe67000d650434",
      "f8951ec2b4c6480692d087fec1dddcae",
      "37a59015ddd94773b802be9eb99bcf80",
      "ddf9671e7f1c4e0c97648ec90880d64b",
      "b2fa5e2513644ecd99219f6fca2c2ef0",
      "70f90a1c020c4a89becb6afa253e27cd",
      "39d4b2a964c940f0a9acfb447614d7be",
      "a227f527ccee4b31b9e3017f72271da9",
      "991d2891c03449fabacf202e6ec46aee",
      "34c4c2c81b6c468f9c91b3059ee2555f",
      "1863a601c87543f6b37e70c2cae3cdfc",
      "d2cea946bf6845f981c08f77fccdf825",
      "e32bd31b28e74b7a8b95d2d44ce85818",
      "c1446387c32448c8884e517b4f5d2efe",
      "80cf9338ce014c40a691c40805b48cae",
      "688e1feb0894426daf3f31e114f5959a",
      "3f980a46d69a47e4abf7266bba36dd4e",
      "ab7f904026244328bdddea4a705fd947",
      "3bcff167eb9e47fdb9f934b1112b1c9c",
      "663f98bf7530478baecf2a7a02bef1ac"
     ]
    },
    "id": "NlaMeqQlHk4m",
    "outputId": "c8b7feb6-e747-4db6-e523-94c6c91bcfb5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69112408bb6d46fbbe9d950fca61784b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a0baef32724caa9ea3c48048c39f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af18b18e70e240e786b128291ab95488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c4c2c81b6c468f9c91b3059ee2555f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/363M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForMaskedLM: ['activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "# redirect stdout to a buffer\n",
    "stdout_buffer = StringIO()\n",
    "sys.stdout = stdout_buffer\n",
    "\n",
    "# run lexsub_main.py script with lexsub_trial.xml input\n",
    "sys.argv = ['lexsub_xml.py', 'lexsub_trial.xml']\n",
    "bert_predictor = BertPredictor()\n",
    "\n",
    "# read lexsub_trial.xml file and apply smurf_predictor function to each context\n",
    "for context in read_lexsub_xml(sys.argv[1]):\n",
    "    prediction = bert_predictor.predict(context) \n",
    "    print(\"{}.{} {} :: {}\".format(context.lemma, context.pos, context.cid, prediction))\n",
    "\n",
    "# redirect stdout back to the console\n",
    "sys.stdout = sys.__stdout__\n",
    "\n",
    "# save output to smurf.predict file\n",
    "with open('p5_bert.predict', 'w') as f:\n",
    "  f.write(stdout_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_imzQHzL2fim"
   },
   "source": [
    "**perl score.pl p5_bert.predict gold.trial**\n",
    "\n",
    "Total = 298, attempted = 298\n",
    "\n",
    "precision = 0.123, recall = 0.123 \n",
    "\n",
    "Total with mode 206 attempted 206 \n",
    "\n",
    "precision = 0.184, recall = 0.184\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhipET3w4lma"
   },
   "source": [
    "**Part 6: Other ideas? (10 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "xMuKZhDO4rBF"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def wn_refined_predictor(context: Context) -> str:\n",
    "    #part 6 Change made compared with wn_simple_lesk_predictor in part 3\n",
    "    #Changed the way the score is calculated. Instead of adding up the counts, I used an exponential function to give more weight to the overlap between the context and the synset.\n",
    "    #Used Python's built-in set data type to eliminate duplicate words in the synset and the overlap, rather than using lists and manually checking for duplicates.\n",
    "    #Removed unnecessary variable assignments and redundant code.\n",
    "    \n",
    "    stopwords_set = set(stopwords.words('english'))\n",
    "    leftright = [x.lower() for x in context.left_context + context.right_context]\n",
    "    leftright_clear = [x for x in leftright if x not in stopwords_set]\n",
    "    \n",
    "    max_score = 0\n",
    "    result = None\n",
    "    synlist = set()\n",
    "    \n",
    "    for l1 in wn.lemmas(context.lemma, pos=context.pos):\n",
    "        overlap = set()\n",
    "        score = 0\n",
    "        syn = l1.synset()\n",
    "        \n",
    "        # Get all example and definition sentences\n",
    "        df = syn.examples()[:]\n",
    "        df.append(syn.definition())\n",
    "        for hyper in syn.hypernyms():\n",
    "            df.append(hyper.definition())\n",
    "            df += hyper.examples()\n",
    "        \n",
    "        \n",
    "        for sentence in df:\n",
    "            synlist |= set(tokenize(sentence.lower()))\n",
    "        \n",
    "        for word in synlist:\n",
    "            if word in leftright_clear and word not in overlap:\n",
    "                overlap.add(word)\n",
    " \n",
    "        for lem in syn.lemmas():\n",
    "            if lem.name().lower() != context.lemma:\n",
    "                score = len(overlap) + math.exp(l1.count()) + math.exp(lem.count())\n",
    "                if score > max_score:\n",
    "                    max_score = score\n",
    "                    result = lem.name().replace('_', ' ')\n",
    "    \n",
    "    return result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "f-6wNZ6xkbAw"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "# redirect stdout to a buffer\n",
    "stdout_buffer = StringIO()\n",
    "sys.stdout = stdout_buffer\n",
    "\n",
    "# run lexsub_main.py script with lexsub_trial.xml input\n",
    "sys.argv = ['lexsub_xml.py', 'lexsub_trial.xml']\n",
    "\n",
    "# read lexsub_trial.xml file and apply smurf_predictor function to each context\n",
    "for context in read_lexsub_xml(sys.argv[1]):\n",
    "    prediction = wn_refined_predictor(context) \n",
    "    print(\"{}.{} {} :: {}\".format(context.lemma, context.pos, context.cid, prediction))\n",
    "\n",
    "# redirect stdout back to the console\n",
    "sys.stdout = sys.__stdout__\n",
    "\n",
    "# save output to smurf.predict file\n",
    "with open('p6_refined.predict', 'w') as f:\n",
    "  f.write(stdout_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziOtifJH67CE"
   },
   "source": [
    "**perl score.pl p6_refined.predict gold**\n",
    "Total = 298, attempted = 298\n",
    "\n",
    "precision = 0.094, recall = 0.094\n",
    "\n",
    "Total with mode 206 attempted 206\n",
    "\n",
    "precision = 0.121, recall = 0.121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nne8tt8R7DGt"
   },
   "source": [
    "# The best predictor is part 5 which is the distilbert-base-uncased bert language model from hugging face "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLZh42XM7Wq3"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "# redirect stdout to a buffer\n",
    "stdout_buffer = StringIO()\n",
    "sys.stdout = stdout_buffer\n",
    "\n",
    "# run lexsub_main.py script with lexsub_trial.xml input\n",
    "sys.argv = ['lexsub_xml.py', 'lexsub_trial.xml']\n",
    "bert_predictor = BertPredictor()\n",
    "\n",
    "# read lexsub_trial.xml file and apply smurf_predictor function to each context\n",
    "for context in read_lexsub_xml(sys.argv[1]):\n",
    "    prediction = bert_predictor.predict(context) \n",
    "    print(\"{}.{} {} :: {}\".format(context.lemma, context.pos, context.cid, prediction))\n",
    "\n",
    "# redirect stdout back to the console\n",
    "sys.stdout = sys.__stdout__\n",
    "\n",
    "# save output to smurf.predict file\n",
    "with open('final_best.predict', 'w') as f:\n",
    "  f.write(stdout_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvxmXDsOH2-_"
   },
   "source": [
    "#Take a try of Bert model from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQQiEpN5H2b_",
    "outputId": "bed5b084-87bd-45fe-ccf2-26ebad1cbc52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForMaskedLM: ['activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import tensorflow as tf\n",
    "model = transformers.TFDistilBertForMaskedLM.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "81ehtVUkGB7E"
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbTdnoQWGGm2",
    "outputId": "130ee4e3-0fd5-4592-f3bc-32ae71c96fe0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['if',\n",
       " 'your',\n",
       " 'money',\n",
       " 'is',\n",
       " 'tight',\n",
       " ',',\n",
       " 'don',\n",
       " \"'\",\n",
       " 't',\n",
       " 'cut',\n",
       " 'corners',\n",
       " '.']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"If your money is tight, don't cut corners.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "wA2gnqnIGKqw"
   },
   "outputs": [],
   "source": [
    "input_toks = tokenizer.encode(\"If your money is tight, don't cut corners\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgZCl7fIGLfE",
    "outputId": "fde64c4c-6f33-48ee-ab11-e695885984f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2065, 2115, 2769, 2003, 4389, 1010, 2123, 1005, 1056, 3013, 8413, 102]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IbbpgXJGSQ7",
    "outputId": "cbf6d9f8-86a2-4e02-f720-8c2d9d9c46e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'if',\n",
       " 'your',\n",
       " 'money',\n",
       " 'is',\n",
       " 'tight',\n",
       " ',',\n",
       " 'don',\n",
       " \"'\",\n",
       " 't',\n",
       " 'cut',\n",
       " 'corners',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(input_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "I_jIqgyCGVXf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "input_mat = np.array(input_toks).reshape((1,-1))  # get a 1 x len(input_toks) matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "FK0QkbnWGXJi"
   },
   "outputs": [],
   "source": [
    "outputs = model.predict(input_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "m9SLvNWIGXw6"
   },
   "outputs": [],
   "source": [
    "predictions = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfG6KMPmIUxa",
    "outputId": "e08b5057-34b8-4d4f-e1e4-de81976e5817"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 13, 30522)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oq1bmOGnIVvS",
    "outputId": "3c1de08d-25af-43bc-acbe-6bd85171d293"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.63325  , -9.816515 , -9.48042  , ..., -8.62085  , -6.931812 ,\n",
       "       -4.4419727], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "NwK1YMwJIYvG"
   },
   "outputs": [],
   "source": [
    "best_words = np.argsort(predictions[0][5])[::-1] # Sort in increasing order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-r0l1BiIa2t",
    "outputId": "e34242db-7249-491d-df1f-e94fd3f1e680"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4389,  2485,  6065, ..., 25084, 12112, 24546])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51m21qUVIdf1",
    "outputId": "d7de3663-ef67-4469-dc4c-1d80eb1d25cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tight',\n",
       " 'close',\n",
       " 'loose',\n",
       " 'deep',\n",
       " 'big',\n",
       " 'tighter',\n",
       " 'tied',\n",
       " 'firm',\n",
       " 'hard',\n",
       " 'down']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(best_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "U_C0OAo1Ihqc"
   },
   "outputs": [],
   "source": [
    "input_toks = tokenizer.encode(\"If your money is [MASK], don't cut corners\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "01Kd3_zTIidl"
   },
   "outputs": [],
   "source": [
    "input_mat = np.array(input_toks).reshape((1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "E5ZfnPGkIj-Y"
   },
   "outputs": [],
   "source": [
    "outputs = model.predict(input_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "UjXQ4SKDIphj"
   },
   "outputs": [],
   "source": [
    "predictions = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "ifKmJzD7IlZK"
   },
   "outputs": [],
   "source": [
    "best_words = np.argsort(predictions[0][5])[::-1] # Sort in increasing order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EGdl6HBKIs2C",
    "outputId": "ee10f683-4ca6-41b2-9136-0400a9a8367e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stolen',\n",
       " 'wasted',\n",
       " 'worthless',\n",
       " 'dirty',\n",
       " 'yours',\n",
       " 'lost',\n",
       " 'money',\n",
       " 'worth',\n",
       " 'good',\n",
       " 'bad']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(best_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "9KOZkGm17gX7"
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html /content/drive/MyDrive/dh3071_hw4_files/lexusb_main.ipynb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0ad870277b7a44c7ac5b2b7153490556": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1863a601c87543f6b37e70c2cae3cdfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80cf9338ce014c40a691c40805b48cae",
      "placeholder": "​",
      "style": "IPY_MODEL_688e1feb0894426daf3f31e114f5959a",
      "value": "Downloading tf_model.h5: 100%"
     }
    },
    "1e1aa05bfa554c279be1e75639a45568": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "308468a23e3d4216bd86d3955ecfb0bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "30b46cdf9f0f4202bdc37151d84f4d05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfef250ce1fd487e8a74988e2be0bc3c",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_308468a23e3d4216bd86d3955ecfb0bc",
      "value": 231508
     }
    },
    "345f94b167a04a42bd1911a85d0451be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "34c4c2c81b6c468f9c91b3059ee2555f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1863a601c87543f6b37e70c2cae3cdfc",
       "IPY_MODEL_d2cea946bf6845f981c08f77fccdf825",
       "IPY_MODEL_e32bd31b28e74b7a8b95d2d44ce85818"
      ],
      "layout": "IPY_MODEL_c1446387c32448c8884e517b4f5d2efe"
     }
    },
    "37a59015ddd94773b802be9eb99bcf80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39d4b2a964c940f0a9acfb447614d7be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3bcff167eb9e47fdb9f934b1112b1c9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ce388044a5e4cf688478b6940528dc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f980a46d69a47e4abf7266bba36dd4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48058f94ee934e7d82cb1f023a0d30e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4962e3fcde58489599821123acaed1e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ddf9671e7f1c4e0c97648ec90880d64b",
      "placeholder": "​",
      "style": "IPY_MODEL_b2fa5e2513644ecd99219f6fca2c2ef0",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "4a9e62f3126541fb85dfd0c0e051a926": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_684e44e1aa9c4278b98831f81e581f83",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_345f94b167a04a42bd1911a85d0451be",
      "value": 28
     }
    },
    "5fe8fda641f84b2ebd4e31eeae816c23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b134205696fd40429c728af71dfa773c",
      "placeholder": "​",
      "style": "IPY_MODEL_cb48ce867afc485483a5d3ad68887585",
      "value": " 232k/232k [00:00&lt;00:00, 1.75MB/s]"
     }
    },
    "663f98bf7530478baecf2a7a02bef1ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "684e44e1aa9c4278b98831f81e581f83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "688e1feb0894426daf3f31e114f5959a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69112408bb6d46fbbe9d950fca61784b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ad9ffc2251f84964a2189cf609122245",
       "IPY_MODEL_30b46cdf9f0f4202bdc37151d84f4d05",
       "IPY_MODEL_5fe8fda641f84b2ebd4e31eeae816c23"
      ],
      "layout": "IPY_MODEL_ebe52d425b7143d980da5b3eb3c36e50"
     }
    },
    "70f90a1c020c4a89becb6afa253e27cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80cf9338ce014c40a691c40805b48cae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "823d62fffaea47d98833a8840e92c834": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9412d2c6e1004b33a5a080aab769deac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "991d2891c03449fabacf202e6ec46aee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c6d381826674cdfa0bdae5624abb881": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9412d2c6e1004b33a5a080aab769deac",
      "placeholder": "​",
      "style": "IPY_MODEL_0ad870277b7a44c7ac5b2b7153490556",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "a227f527ccee4b31b9e3017f72271da9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab7f904026244328bdddea4a705fd947": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ad9ffc2251f84964a2189cf609122245": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d59f3d64647a44fa824fdcf971a33de8",
      "placeholder": "​",
      "style": "IPY_MODEL_48058f94ee934e7d82cb1f023a0d30e7",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "af18b18e70e240e786b128291ab95488": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4962e3fcde58489599821123acaed1e6",
       "IPY_MODEL_c840aebd8bb348549cfe67000d650434",
       "IPY_MODEL_f8951ec2b4c6480692d087fec1dddcae"
      ],
      "layout": "IPY_MODEL_37a59015ddd94773b802be9eb99bcf80"
     }
    },
    "b134205696fd40429c728af71dfa773c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2fa5e2513644ecd99219f6fca2c2ef0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bccc262cd49f4e3ab2a04c9c2dbec77d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ce388044a5e4cf688478b6940528dc5",
      "placeholder": "​",
      "style": "IPY_MODEL_1e1aa05bfa554c279be1e75639a45568",
      "value": " 28.0/28.0 [00:00&lt;00:00, 1.36kB/s]"
     }
    },
    "bfef250ce1fd487e8a74988e2be0bc3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1446387c32448c8884e517b4f5d2efe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2a0baef32724caa9ea3c48048c39f70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9c6d381826674cdfa0bdae5624abb881",
       "IPY_MODEL_4a9e62f3126541fb85dfd0c0e051a926",
       "IPY_MODEL_bccc262cd49f4e3ab2a04c9c2dbec77d"
      ],
      "layout": "IPY_MODEL_823d62fffaea47d98833a8840e92c834"
     }
    },
    "c840aebd8bb348549cfe67000d650434": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70f90a1c020c4a89becb6afa253e27cd",
      "max": 483,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_39d4b2a964c940f0a9acfb447614d7be",
      "value": 483
     }
    },
    "cb48ce867afc485483a5d3ad68887585": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d2cea946bf6845f981c08f77fccdf825": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f980a46d69a47e4abf7266bba36dd4e",
      "max": 363423424,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ab7f904026244328bdddea4a705fd947",
      "value": 363423424
     }
    },
    "d59f3d64647a44fa824fdcf971a33de8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddf9671e7f1c4e0c97648ec90880d64b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e32bd31b28e74b7a8b95d2d44ce85818": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bcff167eb9e47fdb9f934b1112b1c9c",
      "placeholder": "​",
      "style": "IPY_MODEL_663f98bf7530478baecf2a7a02bef1ac",
      "value": " 363M/363M [00:01&lt;00:00, 219MB/s]"
     }
    },
    "ebe52d425b7143d980da5b3eb3c36e50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8951ec2b4c6480692d087fec1dddcae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a227f527ccee4b31b9e3017f72271da9",
      "placeholder": "​",
      "style": "IPY_MODEL_991d2891c03449fabacf202e6ec46aee",
      "value": " 483/483 [00:00&lt;00:00, 21.5kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
